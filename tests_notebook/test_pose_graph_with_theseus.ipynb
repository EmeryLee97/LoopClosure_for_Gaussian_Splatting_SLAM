{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2874f1-0cf9-4553-b261-ea22199bc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import theseus as th\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Union, List, Tuple, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb0f957f-6a76-4592-b42e-d06f08330ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def torch2np(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\" Converts a PyTorch tensor to a NumPy ndarray.\n",
    "    Args:\n",
    "        tensor: The PyTorch tensor to convert.\n",
    "    Returns:\n",
    "        A NumPy ndarray with the same data and dtype as the input tensor.\n",
    "    \"\"\"\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ef1574-9a67-4c4f-8a43-f9bf1c4aa889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSLAMEdge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vertex_idx_i: int,\n",
    "        vertex_idx_j: int,\n",
    "        relative_pose: th.SE3,\n",
    "        cost_weight: th.CostWeight\n",
    "    ):\n",
    "        self.vertex_idx_i = vertex_idx_i\n",
    "        self.vertex_idx_j = vertex_idx_j\n",
    "        self.relative_pose = relative_pose\n",
    "        self.cost_weight = cost_weight\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self.weight.to(*args, **kwargs)\n",
    "        self.relative_pose.to(*args, **kwargs)\n",
    "\n",
    "\n",
    "class GaussianSLAMPoseGraph:\n",
    "    def __init__(\n",
    "        self, \n",
    "        requires_auto_grad = True\n",
    "    ):\n",
    "        self._requires_auto_grad = requires_auto_grad\n",
    "        self._objective = th.Objective()\n",
    "        self._theseus_inputs = {} \n",
    "\n",
    "    def add_odometry_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        relative_pose, cost_weight = edge.relative_pose, edge.cost_weight\n",
    "\n",
    "        #gaussian_means_th = th.Point3(\n",
    "            #tensor=gaussian_means,\n",
    "            #name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        optim_vars = vertex_i, vertex_j\n",
    "        #aux_vars = relative_pose, gaussian_means_th\n",
    "        if self._requires_auto_grad:\n",
    "            for point in gaussian_means:\n",
    "                point_th = th.Point3(tensor=point)\n",
    "                aux_vars = relative_pose, point_th\n",
    "                cost_function = th.AutoDiffCostFunction( # is the 3rd input correct?\n",
    "                    optim_vars, dense_surface_alignment, 3, cost_weight, aux_vars\n",
    "                )\n",
    "                self._objective.add(cost_function)\n",
    "                \n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def add_loop_closure_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.tensor,\n",
    "            coefficient: float # hyperparameter, not the same as in the paper\n",
    "        ):\n",
    "\n",
    "        relative_pose = edge.relative_pose\n",
    "        cost_weight_alignment = edge.cost_weight # for dense surface alignment\n",
    "\n",
    "        l_ij = th.Vector(tensor=torch.ones(1, 1), name=f\"line_process_{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "        #gaussian_means_th = th.Point3(\n",
    "            #tensor=gaussian_means, \n",
    "            #name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        optim_vars = vertex_i, vertex_j, l_ij\n",
    "        #aux_vars = relative_pose, gaussian_means_th\n",
    "\n",
    "        cost_weight_line_process = th.ScaleCostWeight(coefficient) # for line process\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            for point in gaussian_means:\n",
    "                point_th = th.Point3(tensor=point)\n",
    "                aux_vars = relative_pose, point_th\n",
    "                cost_function = th.AutoDiffCostFunction(\n",
    "                    optim_vars, dense_surface_alignment, 3, cost_weight_alignment, aux_vars)\n",
    "                self._objective.add(cost_function)\n",
    "\n",
    "            optim_vars = l_ij,\n",
    "            cost_function = th.AutoDiffCostFunction(\n",
    "                    optim_vars, line_process, 1, cost_weight_line_process) # auxiliary variables can be not declared\n",
    "            self._objective.add(cost_function)\n",
    "        \n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor,\n",
    "                l_ij.name: l_ij.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, max_iterations=1e3, step_size=0.01, track_best_solution=True, verbose=False):\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective=self._objective,\n",
    "            max_iterations=max_iterations,\n",
    "            step_size=step_size)\n",
    "        \n",
    "        layer = th.TheseusLayer(optimizer)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, info = layer.forward(\n",
    "                self._theseus_inputs, \n",
    "                optimizer_kwargs={\"track_best_solution\":track_best_solution, \"verbose\":verbose}\n",
    "                )\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dbfbd67-6cea-4762-baa9-7a70a5bbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_surface_alignment(\n",
    "        optim_vars: Union[Tuple[th.SE3, th.SE3], Tuple[th.SE3, th.SE3, th.Vector]],\n",
    "        aux_vars: Tuple[th.SE3, th.Point3]\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the dense surface alignment error between two vertices, can be used as the error\n",
    "    function input to instantiate a th.CostFunction variable\n",
    "\n",
    "    Args:\n",
    "        optim_vars: optimizaiton variables registered in cost function, should contain\n",
    "            pose_i, pose_j: correction matrix for pose i, j\n",
    "            l_ij (optional): line process coefficient\n",
    "\n",
    "        aux_vars: auxiliary variables registered in cost function, should contain\n",
    "            relative_pose: constraint between vertex_i and vertex_j\n",
    "            gaussian_means_i: mean positions of the 3D Gaussians inside camera frustum, \n",
    "                represented in coordinate i and coordinate (those in coordinate j are not needed)\n",
    "\n",
    "    Returns:\n",
    "        square root of global place recognition error\n",
    "    \"\"\"\n",
    "    # determine whether the edge is odometry edge or loop closure edge\n",
    "    tuple_size = len(optim_vars)\n",
    "    if tuple_size == 2:\n",
    "        pose_i, pose_j = optim_vars\n",
    "    elif tuple_size == 3:\n",
    "        pose_i, pose_j, l_ij = optim_vars\n",
    "    else:\n",
    "        raise ValueError(f\"optim_vars tuple size is {tuple_size}, which can only be 2 or 3.\")\n",
    "    relative_pose, gaussian_means_i = aux_vars\n",
    "    \n",
    "    # transform all points in coordinate i and j to world coordinate\n",
    "    gaussian_means_i_transformed: th.Point3 = pose_i.transform_from(gaussian_means_i)\n",
    "    gaussian_means_j_transformed: th.Point3 = pose_j.transform_from(\n",
    "        relative_pose.transform_from(gaussian_means_i))\n",
    "\n",
    "    residual = (gaussian_means_i_transformed - gaussian_means_j_transformed).tensor\n",
    "\n",
    "    # check if this error function is used for odometry edge or loop edge\n",
    "    if tuple_size == 2:\n",
    "        return residual\n",
    "    else:\n",
    "        return torch.sqrt(l_ij.tensor) * residual\n",
    "\n",
    "\n",
    "def line_process(optim_vars: th.Vector, aux_vars=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the line process error of a loop closrue edge, can be used as the error\n",
    "    input to instantiate a th.CostFunction variable\n",
    "\n",
    "    Args:\n",
    "        optim_vars:\n",
    "            l_ij: jointly optimized weight (l_ij âˆˆ [0, 1]) over the loop edges\n",
    "            (note that the scaling factor mu is considered as cost_weight)\n",
    "\n",
    "    Returns:\n",
    "        square root of line process error\n",
    "    \"\"\"\n",
    "    l_ij, = optim_vars\n",
    "    return l_ij.tensor.sqrt() - 1\n",
    "\n",
    "\n",
    "def match_gaussian_means(\n",
    "        pts_1: torch.tensor,\n",
    "        pts_2: torch.tensor,\n",
    "        transformation: torch.tensor,\n",
    "        epsilon:float=10e-2\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Select inlier correspondences from two Gaussian clouds, use kd-tree to speed up\n",
    "\n",
    "    Args:\n",
    "        pts_1, pts_2: mean positions of 3D Gaussians\n",
    "        transformation: prior transformation matrix from one Gaussian cloud to the other\n",
    "        epsilon: threshold for finding inlier correspondence\n",
    "\n",
    "    Returns:\n",
    "        a list contains tuples of matching indices\n",
    "    \"\"\"\n",
    "    if transformation.size() != torch.Size([4, 4]):\n",
    "        raise ValueError(f\"The size of input transformation matrix must be (4, 4), but get {transformation.size()}\")\n",
    "\n",
    "    if pts_1.size(-1) != 1:\n",
    "        pts_1 = pts_1.unsqueeze(-1)\n",
    "\n",
    "    rotation = transformation[:3, :3]\n",
    "    translation = transformation[:3, 3]\n",
    "    pts_1_new = (rotation @ pts_1).squeeze() + translation\n",
    "\n",
    "    pts_1_numpy = torch2np(pts_1_new)\n",
    "    pts_2_numpy = torch2np(pts_2)\n",
    "    pts2_kdtree = KDTree(pts_2_numpy)\n",
    "\n",
    "    _, query_idx = pts2_kdtree.query(pts_1_numpy, distance_upper_bound=epsilon, workers=-1)\n",
    "\n",
    "    data_size = pts_1.size()[0]\n",
    "    res_list = []\n",
    "    for i in range(data_size):\n",
    "        if query_idx[i] != data_size:\n",
    "            res_list.append((i, query_idx[i]))\n",
    "\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7ca585e-09a9-4901-92b7-852fd4234c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(\n",
    "        num_pts: int = 100, \n",
    "        num_poses: int = 10, \n",
    "        translation_noise: float = 0.05, \n",
    "        rotation_noise: float = 0.1, \n",
    "        batch_size: int = 1\n",
    "        ) -> Tuple[List[th.Point3], List[th.SE3], List[th.SE3], List[GaussianSLAMEdge]]:\n",
    "    \"\"\"\n",
    "    create point clouds represented in different coordinates, record their ground truth \n",
    "    absolute pose, noisy absolute pose, also return an empty list to put loop edges\n",
    "\n",
    "    Returns:\n",
    "        point_list: a list stores points clouds, represented in different coordinates\n",
    "        abs_pose_list_gt: a list stores ground truth absolute poses\n",
    "        abs_pose_list: a list stores noisy (odometry) absolute poses\n",
    "        edge_list: a list stores custum GaussianSLAMEdge\n",
    "        TODO: Do I need to put the first edge that connets vertex_0 and vertex_1 into the list?\n",
    "    \"\"\"\n",
    "\n",
    "    dtype = torch.float32 # will get error if changed to torch.float64, don't know why\n",
    "\n",
    "    points_0 = th.Point3(2*torch.rand(num_pts, 3)-1, name=\"POINT_CLOUD__0\") # initial points in world frame\n",
    "    point_list = [points_0] # represented in different frames\n",
    "    abs_pose_list_gt = [] # frame i to world frame\n",
    "    abs_pose_list = [] # frame i to world frame (noisy)\n",
    "    edge_list = []\n",
    "\n",
    "    abs_pose_list_gt.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4, dtype=dtype), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3_GT__0\"\n",
    "        ))\n",
    "    \n",
    "    abs_pose_list.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4, dtype=dtype), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3__0\"\n",
    "        ))\n",
    "\n",
    "    for idx in range(1, num_poses):\n",
    "\n",
    "        # ground truth relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_gt = th.SE3.exp_map(\n",
    "            torch.cat([torch.rand(batch_size, 3)-0.5, 2.0 * torch.rand(batch_size, 3)-1], dim=1),\n",
    "        )\n",
    "\n",
    "        # generate points represented in frame_{idx}\n",
    "        points = relative_pose_gt.transform_from(point_list[-1])\n",
    "        points.name = f\"POINT_CLOUD__{idx}\"\n",
    "        point_list.append(points)\n",
    "\n",
    "        # add noise to get odometry relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                translation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                rotation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "        )\n",
    "\n",
    "        relative_pose = cast(th.SE3, relative_pose_noise.compose(relative_pose_gt))\n",
    "        relative_pose.name = f\"EDGE_SE3__{idx-1}_{idx}\"\n",
    "        weight = th.ScaleCostWeight(1.0, name=f\"EDGE_WEIGHT__{idx-1}_{idx}\")\n",
    "\n",
    "        # absolute pose of frame_{idx}\n",
    "        absolute_pose_gt = cast(th.SE3, abs_pose_list_gt[-1].compose(relative_pose_gt.inverse()))\n",
    "        absolute_pose_gt.name = f\"VERTEX_SE3_GT__{idx}\"\n",
    "\n",
    "        absolute_pose = cast(th.SE3, abs_pose_list[-1].compose(relative_pose.inverse()))\n",
    "        absolute_pose.name = f\"VERTEX_SE3__{idx}\"\n",
    "\n",
    "        abs_pose_list_gt.append(absolute_pose_gt)\n",
    "        abs_pose_list.append(absolute_pose)\n",
    "\n",
    "        # construct odometry edge between vertex_{idx-1} and vertex_{idx}\n",
    "        edge_list.append(GaussianSLAMEdge(idx-1, idx, relative_pose, weight))\n",
    "\n",
    "    return point_list, abs_pose_list_gt, abs_pose_list, edge_list\n",
    "\n",
    "\n",
    "def add_loop_data(\n",
    "        i: int, \n",
    "        j: int, \n",
    "        abs_pose_list_gt: List[th.SE3], \n",
    "        edge_list: List[GaussianSLAMEdge],\n",
    "        coefficient: float = 1.0,\n",
    "        measurement_noise:float = 0.01,\n",
    "        batch_size: int = 1\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Add loop closure between two arbitray coordinates i and j (i < j), and stores generated edge\n",
    "    \"\"\"\n",
    "\n",
    "    if i >= j:\n",
    "        raise ValueError(f\"The first frame index {i} is greater than the second frame index {j}!\")\n",
    "\n",
    "    abs_pose_i_gt = abs_pose_list_gt[i]\n",
    "    abs_pose_j_gt = abs_pose_list_gt[j]\n",
    "    rel_pose_ij_gt = th.SE3.compose(abs_pose_j_gt.inverse(), abs_pose_i_gt)\n",
    "    rel_pose_ij_gt.name = f\"EDGE_SE3_GT__{i}_{j}\"\n",
    "\n",
    "    relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "            )\n",
    "    rel_pose_ij = cast(th.SE3, relative_pose_noise.compose(rel_pose_ij_gt))\n",
    "    rel_pose_ij.name = f\"EDGE_SE3__{i}_{j}\"\n",
    "\n",
    "    cost_weight = th.ScaleCostWeight(coefficient, name=f\"EDGE_WEIGHT__{i}_{j}\")\n",
    "    edge = GaussianSLAMEdge(i, j, rel_pose_ij, cost_weight)\n",
    "    edge_list.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f203f103-9f98-4192-a018-1c5994203e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_1: SE3(matrix=tensor([[[ 0.9150,  0.2735,  0.2967,  0.0066],\n",
      "         [ 0.0284,  0.6898, -0.7234,  0.1104],\n",
      "         [-0.4026,  0.6703,  0.6234, -0.5111]]])), name=VERTEX_SE3__1)\n",
      "vertex_2: SE3(matrix=tensor([[[ 0.4265, -0.2118,  0.8793,  0.2306],\n",
      "         [ 0.8338,  0.4689, -0.2914, -0.0354],\n",
      "         [-0.3506,  0.8575,  0.3766, -0.5623]]])), name=VERTEX_SE3__2)\n",
      "vertex_3: SE3(matrix=tensor([[[ 0.4105,  0.7207,  0.5587, -0.1647],\n",
      "         [ 0.7539,  0.0764, -0.6525, -0.2323],\n",
      "         [-0.5129,  0.6891, -0.5120, -0.3413]]])), name=VERTEX_SE3__3)\n",
      "vertex_4: SE3(matrix=tensor([[[ 0.7916, -0.2911,  0.5372,  0.2179],\n",
      "         [ 0.6110,  0.3723, -0.6986,  0.0327],\n",
      "         [ 0.0034,  0.8813,  0.4726, -0.4036]]])), name=VERTEX_SE3__4)\n",
      "vertex_5: SE3(matrix=tensor([[[ 0.8226,  0.4849,  0.2970, -0.0891],\n",
      "         [ 0.3694, -0.0587, -0.9274,  0.2681],\n",
      "         [-0.4322,  0.8726, -0.2274, -0.5726]]])), name=VERTEX_SE3__5)\n",
      "vertex_6: SE3(matrix=tensor([[[ 0.3114, -0.4973,  0.8097,  0.2376],\n",
      "         [ 0.9480,  0.1040, -0.3007,  0.6053],\n",
      "         [ 0.0653,  0.8613,  0.5039, -0.5701]]])), name=VERTEX_SE3__6)\n",
      "vertex_7: SE3(matrix=tensor([[[ 0.6224, -0.3777,  0.6855,  0.3813],\n",
      "         [ 0.7781,  0.3934, -0.4897,  0.5313],\n",
      "         [-0.0847,  0.8382,  0.5387, -0.9256]]])), name=VERTEX_SE3__7)\n",
      "vertex_8: SE3(matrix=tensor([[[ 0.7048,  0.6476, -0.2896,  0.2020],\n",
      "         [-0.2426, -0.1636, -0.9562,  0.6761],\n",
      "         [-0.6666,  0.7442,  0.0418, -1.1243]]])), name=VERTEX_SE3__8)\n",
      "vertex_9: SE3(matrix=tensor([[[ 0.1865,  0.9471, -0.2614, -0.2037],\n",
      "         [-0.5057, -0.1355, -0.8520,  0.5148],\n",
      "         [-0.8423,  0.2910,  0.4537, -1.4464]]])), name=VERTEX_SE3__9)\n",
      "Constructing a pose graph for Gaussian Splatting SLAM.\n",
      "adding edge 0 to pose graph, current edge is an odometry edge.\n",
      "adding edge 1 to pose graph, current edge is an odometry edge.\n",
      "adding edge 2 to pose graph, current edge is an odometry edge.\n",
      "adding edge 3 to pose graph, current edge is an odometry edge.\n",
      "adding edge 4 to pose graph, current edge is an odometry edge.\n",
      "adding edge 5 to pose graph, current edge is an odometry edge.\n",
      "adding edge 6 to pose graph, current edge is an odometry edge.\n",
      "adding edge 7 to pose graph, current edge is an odometry edge.\n",
      "adding edge 8 to pose graph, current edge is an odometry edge.\n",
      "adding edge 9 to pose graph, current edge is an loop edge.\n"
     ]
    }
   ],
   "source": [
    "point_list, abs_pose_gt_list, abs_pose_list, edge_list = create_data()\n",
    "add_loop_data(1, 9, abs_pose_gt_list, edge_list)\n",
    "print(f\"vertex_1 before optimization: {abs_pose_list[1]}\")\n",
    "print(f\"vertex_2 before optimization: {abs_pose_list[2]}\")\n",
    "print(f\"vertex_3 before optimization: {abs_pose_list[3]}\")\n",
    "print(f\"vertex_4 before optimization: {abs_pose_list[4]}\")\n",
    "print(f\"vertex_5 before optimization: {abs_pose_list[5]}\")\n",
    "print(f\"vertex_6 before optimization: {abs_pose_list[6]}\")\n",
    "print(f\"vertex_7 before optimization: {abs_pose_list[7]}\")\n",
    "print(f\"vertex_8 before optimization: {abs_pose_list[8]}\")\n",
    "print(f\"vertex_9 before optimization: {abs_pose_list[9]}\")\n",
    "\n",
    "print(\"Constructing a pose graph for Gaussian Splatting SLAM.\")\n",
    "pose_graph = GaussianSLAMPoseGraph(requires_auto_grad=True)\n",
    "\n",
    "for idx in range(len(edge_list)):\n",
    "#for idx in range(1):\n",
    "    edge = edge_list[idx]\n",
    "    vertex_idx_i = edge.vertex_idx_i\n",
    "    vertex_idx_j = edge.vertex_idx_j\n",
    "    \n",
    "    vertex_i = abs_pose_list[vertex_idx_i]\n",
    "    vertex_j = abs_pose_list[vertex_idx_j]\n",
    "\n",
    "    if vertex_idx_j - vertex_idx_i == 1:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an odometry edge.\")\n",
    "        pose_graph.add_odometry_edge(vertex_i, vertex_j, edge, point_list[idx])\n",
    "    else:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an loop edge.\")\n",
    "        pose_i_gt, pose_j_gt = abs_pose_gt_list[vertex_idx_i], abs_pose_gt_list[vertex_idx_j]\n",
    "        relative_pose_gt = th.SE3.compose(pose_j_gt.inverse(), pose_i_gt)\n",
    "        inlier_idx = match_gaussian_means(point_list[vertex_idx_i].tensor, point_list[vertex_idx_j].tensor, relative_pose_gt.to_matrix().squeeze(), epsilon=5e-2)\n",
    "        inlier_idx_i = [idx[0] for idx in inlier_idx]\n",
    "        pose_graph.add_loop_closure_edge(vertex_i, vertex_j, edge, point_list[vertex_idx_i][inlier_idx_i], 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726660be-ead6-45f9-bf7a-1f4beba699af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonlinearOptimizerInfo(best_solution={'VERTEX_SE3__0': tensor([[[ 0.9990,  0.0098,  0.0448, -0.0261],\n",
      "         [-0.0071,  0.9982, -0.0600, -0.0721],\n",
      "         [-0.0453,  0.0597,  0.9972,  0.0042]]]), 'VERTEX_SE3__1': tensor([[[ 0.8963,  0.3100,  0.3172, -0.0413],\n",
      "         [ 0.0460,  0.6464, -0.7616,  0.0688],\n",
      "         [-0.4412,  0.6972,  0.5651, -0.4992]]]), 'VERTEX_SE3__2': tensor([[[ 0.4231, -0.1800,  0.8880,  0.1893],\n",
      "         [ 0.8464,  0.4283, -0.3165, -0.0633],\n",
      "         [-0.3234,  0.8855,  0.3336, -0.5677]]]), 'VERTEX_SE3__3': tensor([[[ 0.4057,  0.7344,  0.5441, -0.1936],\n",
      "         [ 0.7689,  0.0476, -0.6376, -0.2527],\n",
      "         [-0.4942,  0.6770, -0.5454, -0.3435]]]), 'VERTEX_SE3__4': tensor([[[ 0.7939, -0.2835,  0.5379,  0.1972],\n",
      "         [ 0.6079,  0.3535, -0.7110,  0.0272],\n",
      "         [ 0.0114,  0.8915,  0.4530, -0.4021]]]), 'VERTEX_SE3__5': tensor([[[ 0.8260,  0.4797,  0.2960, -0.0998],\n",
      "         [ 0.3723, -0.0699, -0.9255,  0.2799],\n",
      "         [-0.4233,  0.8746, -0.2364, -0.5686]]]), 'VERTEX_SE3__6': tensor([[[ 0.3119, -0.5133,  0.7995,  0.2386],\n",
      "         [ 0.9473,  0.1030, -0.3034,  0.6294],\n",
      "         [ 0.0734,  0.8520,  0.5183, -0.5636]]]), 'VERTEX_SE3__7': tensor([[[ 0.6269, -0.4037,  0.6664,  0.4064],\n",
      "         [ 0.7761,  0.3986, -0.4887,  0.5664],\n",
      "         [-0.0683,  0.8235,  0.5632, -0.9166]]]), 'VERTEX_SE3__8': tensor([[[ 0.7341,  0.6122, -0.2937,  0.2543],\n",
      "         [-0.2517, -0.1564, -0.9551,  0.7212],\n",
      "         [-0.6306,  0.7751,  0.0393, -1.1238]]]), 'VERTEX_SE3__9': tensor([[[ 0.2340,  0.9274, -0.2919, -0.1117],\n",
      "         [-0.5234, -0.1328, -0.8417,  0.5622],\n",
      "         [-0.8193,  0.3497,  0.4543, -1.4710]]]), 'line_process_1_9': tensor([[0.8609]])}, status=array([<NonlinearOptimizerStatus.CONVERGED: 1>], dtype=object), converged_iter=tensor([854]), best_iter=tensor([852]), err_history=None, last_err=tensor([0.2506]), best_err=tensor([0.2506]), state_history=None)\n",
      "vertex_1: SE3(matrix=tensor([[[ 0.8629,  0.3218,  0.3898, -0.0103],\n",
      "         [ 0.0318,  0.7351, -0.6772,  0.0947],\n",
      "         [-0.5044,  0.5968,  0.6240, -0.4944]]])), name=VERTEX_SE3_GT__1)\n",
      "vertex_2: SE3(matrix=tensor([[[ 0.2705, -0.0699,  0.9602,  0.2594],\n",
      "         [ 0.8140,  0.5492, -0.1893, -0.0281],\n",
      "         [-0.5141,  0.8328,  0.2055, -0.5441]]])), name=VERTEX_SE3_GT__2)\n",
      "vertex_3: SE3(matrix=tensor([[[ 0.3031,  0.7770,  0.5517, -0.0127],\n",
      "         [ 0.6774,  0.2315, -0.6983, -0.2384],\n",
      "         [-0.6703,  0.5853, -0.4562, -0.2391]]])), name=VERTEX_SE3_GT__3)\n",
      "vertex_4: SE3(matrix=tensor([[[ 0.7719, -0.2876,  0.5670,  0.3043],\n",
      "         [ 0.6308,  0.4573, -0.6269,  0.0111],\n",
      "         [-0.0790,  0.8415,  0.5344, -0.3919]]])), name=VERTEX_SE3_GT__4)\n",
      "vertex_5: SE3(matrix=tensor([[[ 0.8008,  0.4793,  0.3591, -0.0222],\n",
      "         [ 0.3999,  0.0186, -0.9164,  0.2253],\n",
      "         [-0.4459,  0.8775, -0.1768, -0.6251]]])), name=VERTEX_SE3_GT__5)\n",
      "vertex_6: SE3(matrix=tensor([[[ 0.3317, -0.4914,  0.8053,  0.2765],\n",
      "         [ 0.9424,  0.1333, -0.3069,  0.5959],\n",
      "         [ 0.0434,  0.8606,  0.5073, -0.6887]]])), name=VERTEX_SE3_GT__6)\n",
      "vertex_7: SE3(matrix=tensor([[[ 0.6334, -0.3364,  0.6969,  0.4079],\n",
      "         [ 0.7653,  0.4057, -0.4997,  0.4983],\n",
      "         [-0.1146,  0.8498,  0.5144, -1.0873]]])), name=VERTEX_SE3_GT__7)\n",
      "vertex_8: SE3(matrix=tensor([[[ 0.7002,  0.6370, -0.3224,  0.2401],\n",
      "         [-0.3072, -0.1388, -0.9415,  0.6749],\n",
      "         [-0.6445,  0.7583,  0.0985, -1.2283]]])), name=VERTEX_SE3_GT__8)\n",
      "vertex_9: SE3(matrix=tensor([[[ 0.2196,  0.9491, -0.2258, -0.1492],\n",
      "         [-0.6175, -0.0440, -0.7853,  0.4680],\n",
      "         [-0.7553,  0.3119,  0.5764, -1.5246]]])), name=VERTEX_SE3_GT__9)\n"
     ]
    }
   ],
   "source": [
    "#print(pose_graph._objective.error().shape)\n",
    "info = pose_graph.optimize(max_iterations=1e5, step_size=0.01, verbose=False)\n",
    "print(info)\n",
    "print(f\"vertex_1 ground truth: {abs_pose_gt_list[1]}\")\n",
    "print(f\"vertex_2 ground truth: {abs_pose_gt_list[2]}\")\n",
    "print(f\"vertex_3 ground truth: {abs_pose_gt_list[3]}\")\n",
    "print(f\"vertex_4 ground truth: {abs_pose_gt_list[4]}\")\n",
    "print(f\"vertex_5 ground truth: {abs_pose_gt_list[5]}\")\n",
    "print(f\"vertex_6 ground truth: {abs_pose_gt_list[6]}\")\n",
    "print(f\"vertex_7 ground truth: {abs_pose_gt_list[7]}\")\n",
    "print(f\"vertex_8 ground truth: {abs_pose_gt_list[8]}\")\n",
    "print(f\"vertex_9 ground truth: {abs_pose_gt_list[9]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4699c2-bbdf-4092-a7bc-a72648edf144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9),\n",
       " (10, 10),\n",
       " (11, 11),\n",
       " (12, 12),\n",
       " (13, 13),\n",
       " (14, 14),\n",
       " (15, 15),\n",
       " (16, 16),\n",
       " (17, 17),\n",
       " (18, 18),\n",
       " (20, 20),\n",
       " (21, 21),\n",
       " (22, 22),\n",
       " (23, 23),\n",
       " (24, 24),\n",
       " (25, 25),\n",
       " (26, 26),\n",
       " (27, 27),\n",
       " (28, 28),\n",
       " (29, 29),\n",
       " (30, 30),\n",
       " (31, 31),\n",
       " (32, 32),\n",
       " (33, 33),\n",
       " (34, 34),\n",
       " (35, 35),\n",
       " (36, 36),\n",
       " (37, 37),\n",
       " (38, 38),\n",
       " (39, 39),\n",
       " (40, 40),\n",
       " (41, 41),\n",
       " (42, 42),\n",
       " (43, 43),\n",
       " (44, 44),\n",
       " (45, 45),\n",
       " (46, 46),\n",
       " (47, 47),\n",
       " (48, 48),\n",
       " (49, 49),\n",
       " (50, 50),\n",
       " (51, 51),\n",
       " (52, 52),\n",
       " (53, 53),\n",
       " (54, 54),\n",
       " (55, 55),\n",
       " (56, 56),\n",
       " (57, 57),\n",
       " (58, 58),\n",
       " (59, 59),\n",
       " (60, 60),\n",
       " (61, 61),\n",
       " (63, 63),\n",
       " (64, 64),\n",
       " (65, 65),\n",
       " (66, 66),\n",
       " (67, 67),\n",
       " (68, 68),\n",
       " (69, 69),\n",
       " (70, 70),\n",
       " (71, 71),\n",
       " (72, 72),\n",
       " (73, 73),\n",
       " (74, 74),\n",
       " (75, 75),\n",
       " (76, 76),\n",
       " (77, 77),\n",
       " (78, 78),\n",
       " (79, 79),\n",
       " (80, 80),\n",
       " (81, 81),\n",
       " (82, 82),\n",
       " (83, 91),\n",
       " (84, 84),\n",
       " (85, 85),\n",
       " (86, 86),\n",
       " (87, 87),\n",
       " (88, 88),\n",
       " (89, 89),\n",
       " (90, 70),\n",
       " (91, 91),\n",
       " (92, 92),\n",
       " (93, 93),\n",
       " (94, 94),\n",
       " (95, 95),\n",
       " (96, 96),\n",
       " (98, 75),\n",
       " (99, 99)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test match_gaussian_means with hyperparameter\n",
    "pose_0, pose_1 = abs_pose_list[0], abs_pose_list[1]\n",
    "pose_01 = th.SE3.compose(pose_1.inverse(), pose_0).to_matrix().squeeze()\n",
    "idx = match_gaussian_means(point_list[0].tensor, point_list[1].tensor, pose_01)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206da894-824e-41db-abe0-fd7e51474675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7252, -0.3291,  0.4018])\n",
      "tensor([1.1422, 0.6562, 0.1981])\n",
      "SE3(matrix=tensor([[[ 0.8453, -0.5334, -0.0303,  0.3657],\n",
      "         [ 0.3933,  0.5829,  0.7111,  0.2772],\n",
      "         [-0.3616, -0.6130,  0.7025, -0.0236]]])), name=SE3__4633)\n",
      "SE3(matrix=tensor([[[ 0.8714, -0.4903, -0.0183,  0.3830],\n",
      "         [ 0.3392,  0.5750,  0.7445,  0.2756],\n",
      "         [-0.3545, -0.6550,  0.6673, -0.0013]]])), name=EDGE_SE3__0_1)\n"
     ]
    }
   ],
   "source": [
    "print(point_list[0][0, :])\n",
    "print(point_list[1][0, :])\n",
    "print(abs_pose_gt_list[1].inverse())\n",
    "print(edge_list[0].relative_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be0dbfc-5b56-4792-9f6c-a32069693b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([1.1422, 0.6562, 0.1981])\n"
     ]
    }
   ],
   "source": [
    "pose = abs_pose_gt_list[1].inverse().tensor.squeeze()\n",
    "R = pose[:3, :3]\n",
    "t = pose[:3, 3]\n",
    "rel_pose = edge_list[0].relative_pose.tensor.squeeze()\n",
    "print(edge_list[0].vertex_idx_i)\n",
    "#R = rel_pose[:3, :3]\n",
    "#t = rel_pose[:3, -1]\n",
    "\n",
    "\n",
    "print((R @ point_list[0][0, :].unsqueeze(-1)).squeeze()+t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2846d03-6f8b-4f20-85c2-56ab05a25408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
