{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2874f1-0cf9-4553-b261-ea22199bc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import theseus as th\n",
    "import torchlie.functional as lieF # use this instead of th.SE3\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Union, List, Tuple, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0f957f-6a76-4592-b42e-d06f08330ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def torch2np(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\" Converts a PyTorch tensor to a NumPy ndarray.\n",
    "    Args:\n",
    "        tensor: The PyTorch tensor to convert.\n",
    "    Returns:\n",
    "        A NumPy ndarray with the same data and dtype as the input tensor.\n",
    "    \"\"\"\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ef1574-9a67-4c4f-8a43-f9bf1c4aa889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSLAMEdge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vertex_idx_i: int,\n",
    "        vertex_idx_j: int,\n",
    "        relative_pose: th.SE3,\n",
    "        cost_weight: th.CostWeight\n",
    "    ):\n",
    "        self.vertex_idx_i = vertex_idx_i\n",
    "        self.vertex_idx_j = vertex_idx_j\n",
    "        self.relative_pose = relative_pose\n",
    "        self.cost_weight = cost_weight\n",
    "        \n",
    "\n",
    "class GaussianSLAMPoseGraph:\n",
    "    def __init__(\n",
    "        self, \n",
    "        requires_auto_grad = True\n",
    "    ):\n",
    "        self._requires_auto_grad = requires_auto_grad\n",
    "        self._objective = th.Objective()\n",
    "        self._theseus_inputs = {} \n",
    "    \n",
    "    def add_odometry_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            for point in gaussian_means:\n",
    "                cost_function = th.AutoDiffCostFunction(\n",
    "                    optim_vars=[vertex_i, vertex_j], \n",
    "                    err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                    dim=3, \n",
    "                    cost_weight=edge.cost_weight, \n",
    "                    aux_vars=[edge.relative_pose, th.Point3(tensor=point)]\n",
    "                )\n",
    "                self._objective.add(cost_function)\n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    def add_loop_closure_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.tensor,\n",
    "            match_num : int,\n",
    "            tau: float=0.2, # fairly liberal distance threshold\n",
    "        ):\n",
    "\n",
    "        cost_weight_registration = edge.cost_weight # for dense surface alignment\n",
    "        cost_weight_mu = cost_weight_registration.scale.tensor.squeeze() * np.sqrt(match_num) * tau\n",
    "        print(f\"cost_weight_mu = {cost_weight_mu}\")\n",
    "        cost_weight_line_process = th.ScaleCostWeight(cost_weight_mu) # for line process\n",
    "        \n",
    "        l_ij = th.Vector(tensor=torch.ones(1, 1), name=f\"line_process_{edge.vertex_idx_i}_{edge.vertex_idx_j}\")    \n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            for point in gaussian_means:\n",
    "                cost_function_registration = th.AutoDiffCostFunction(\n",
    "                    optim_vars=[vertex_i, vertex_j, l_ij], \n",
    "                    err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                    dim=3, \n",
    "                    cost_weight=cost_weight_registration, \n",
    "                    aux_vars=[edge.relative_pose, th.Point3(tensor=point)]\n",
    "                )\n",
    "                self._objective.add(cost_function_registration)\n",
    "\n",
    "            cost_function_line_process = th.AutoDiffCostFunction(\n",
    "                optim_vars=[l_ij,], \n",
    "                err_fn=GaussianSLAMPoseGraph.line_process, \n",
    "                dim=1, \n",
    "                cost_weight=cost_weight_line_process\n",
    "            ) # auxiliary variables can be not declared\n",
    "            self._objective.add(cost_function_line_process)\n",
    "        \n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor,\n",
    "                l_ij.name: l_ij.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    def _remove_loop_outlier(self, threshold: float, substring=\"line_process\"):\n",
    "        \"\"\" \n",
    "        find all l_ij inside the objective, remove those whose value are smaller than threshold \n",
    "        and all cost functions that are connected to them\n",
    "        (currently implemented with the help of a dictionary called self._theseus_inputs, can it be\n",
    "        directly done with self._objective?)\n",
    "        \"\"\"\n",
    "        for key in self._theseus_inputs.keys():\n",
    "            if substring in key and self._objective.get_optim_var(key).tensor < threshold:\n",
    "                del self._theseus_inputs[key]\n",
    "                for cost_func in self._objective.get_functions_connected_to_optim_var(key):\n",
    "                    self._objective.erase(cost_func.name)\n",
    "\n",
    "    def _optimize(self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective=self._objective,\n",
    "            max_iterations=max_iterations,\n",
    "            step_size=step_size\n",
    "        )\n",
    "        layer = th.TheseusLayer(optimizer)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, info = layer.forward(\n",
    "                #self._theseus_inputs, # 这个要输入吗？\n",
    "                optimizer_kwargs={\"damping\":damping, \"track_best_solution\":track_best_solution, \"verbose\":verbose}\n",
    "                )\n",
    "        return info\n",
    "\n",
    "    def optimize_two_steps(\n",
    "            self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            l_ij_threshold=0.25,\n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        optimization in two steps: \n",
    "        1. optimize with initial guess of all optim variables (T_i, l_ij)\n",
    "        2. remove all l_ij < threshold, and all cost functions that are connected to them,\n",
    "           optimize again with optimized variables\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"First step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        _ = self._optimize(max_iterations, step_size, damping, track_best_solution, verbose)\n",
    "        self._remove_loop_outlier(threshold=l_ij_threshold)\n",
    "        print(f\"Second step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        info = self._optimize(max_iterations, step_size, damping, track_best_solution,verbose)\n",
    "        return info\n",
    "\n",
    "    @ staticmethod\n",
    "    def dense_surface_alignment(\n",
    "        optim_vars: Union[Tuple[th.SE3, th.SE3], Tuple[th.SE3, th.SE3, th.Vector]],\n",
    "        aux_vars: Tuple[th.SE3, th.Point3]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the dense surface alignment error between two vertices, can be used as the error\n",
    "        function input to instantiate a th.CostFunction variable\n",
    "    \n",
    "        Args:\n",
    "            optim_vars: optimizaiton variables registered in cost function, should contain\n",
    "                pose_i, pose_j: correction matrix for pose i, j\n",
    "                l_ij (optional): line process coefficient\n",
    "    \n",
    "            aux_vars: auxiliary variables registered in cost function, should contain\n",
    "                relative_pose: constraint between vertex_i and vertex_j\n",
    "                gaussian_means_i: mean positions of the 3D Gaussians inside camera frustum, \n",
    "                    represented in coordinate i and coordinate (those in coordinate j are not needed).\n",
    "                    should have shape (batch_size, num_points, dim)\n",
    "    \n",
    "        Returns:\n",
    "            square root of global place recognition error\n",
    "        \"\"\"\n",
    "        # determine whether the edge is odometry edge or loop closure edge\n",
    "        tuple_size = len(optim_vars)\n",
    "        if tuple_size == 2:\n",
    "            pose_i, pose_j = optim_vars\n",
    "        elif tuple_size == 3:\n",
    "            pose_i, pose_j, l_ij = optim_vars\n",
    "        else:\n",
    "            raise ValueError(f\"optim_vars tuple size is {tuple_size}, which can only be 2 or 3.\")\n",
    "        relative_pose, gaussian_means_i = aux_vars\n",
    "    \n",
    "        #print(f\"gaussian_means shape = {gaussian_means_i.shape}\")\n",
    "        \n",
    "        # transform all points in coordinate i and j to world coordinate\n",
    "        gaussian_means_i_transformed: th.Point3 = pose_i.transform_from(gaussian_means_i)\n",
    "        gaussian_means_j_transformed: th.Point3 = pose_j.transform_from(\n",
    "            relative_pose.transform_from(gaussian_means_i))\n",
    "    \n",
    "        residual = (gaussian_means_i_transformed - gaussian_means_j_transformed).tensor\n",
    "    \n",
    "        #gaussian_means_w1 = lieF.SE3.transform(pose_i.tensor, gaussian_means_i.tensor)\n",
    "        #gaussian_means_j = lieF.SE3.transform(relative_pose.tensor, gaussian_means_i.tensor)\n",
    "        #gaussian_means_w2 = lieF.SE3.transform(pose_j.tensor, gaussian_means_j)\n",
    "        #residual = gaussian_means_w1 - gaussian_means_w2\n",
    "    \n",
    "        # check if this error function is used for odometry edge or loop edge\n",
    "        if tuple_size == 2:\n",
    "            return residual\n",
    "        else:\n",
    "            return torch.sqrt(l_ij.tensor) * residual\n",
    "\n",
    "    \n",
    "    @ staticmethod\n",
    "    def line_process(optim_vars: th.Vector, aux_vars=None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the line process error of a loop closrue edge, can be used as the error\n",
    "        input to instantiate a th.CostFunction variable\n",
    "    \n",
    "        Args:\n",
    "            optim_vars:\n",
    "                l_ij: jointly optimized weight (l_ij ∈ [0, 1]) over the loop edges\n",
    "                (note that the scaling factor mu is considered as cost_weight)\n",
    "    \n",
    "        Returns:\n",
    "            square root of line process error\n",
    "        \"\"\"\n",
    "        l_ij, = optim_vars\n",
    "        return l_ij.tensor.sqrt() - 1\n",
    "\n",
    "    \n",
    "    @ staticmethod\n",
    "    def match_gaussian_means(\n",
    "        pts_1: torch.tensor,\n",
    "        pts_2: torch.tensor,\n",
    "        transformation: torch.tensor,\n",
    "        epsilon:float=10e-2\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Select inlier correspondences from two Gaussian clouds, use kd-tree to speed up\n",
    "    \n",
    "        Args:\n",
    "            pts_1, pts_2: mean positions of 3D Gaussians\n",
    "            transformation: prior transformation matrix from one Gaussian cloud to the other\n",
    "            epsilon: threshold for finding inlier correspondence\n",
    "    \n",
    "        Returns:\n",
    "            a list contains tuples of matching indices\n",
    "        \"\"\"\n",
    "        if transformation.size() != torch.Size([4, 4]):\n",
    "            raise ValueError(f\"The size of input transformation matrix must be (4, 4), but get {transformation.size()}\")\n",
    "    \n",
    "        if pts_1.size(-1) != 1:\n",
    "            pts_1 = pts_1.unsqueeze(-1)\n",
    "    \n",
    "        if isinstance(pts_1, th.Point3) or isinstance(pts_2, th.Point3):\n",
    "                raise TypeError(\"To be matched points must be torch.Tensor\")\n",
    "    \n",
    "        rotation = transformation[:3, :3]\n",
    "        translation = transformation[:3, 3]\n",
    "        pts_1_new = (rotation @ pts_1).squeeze() + translation\n",
    "    \n",
    "        pts_1_numpy = torch2np(pts_1_new)\n",
    "        pts_2_numpy = torch2np(pts_2)\n",
    "        pts2_kdtree = KDTree(pts_2_numpy)\n",
    "    \n",
    "        _, query_idx = pts2_kdtree.query(pts_1_numpy, distance_upper_bound=epsilon, workers=-1)\n",
    "    \n",
    "        data_size = pts_1.size()[0]\n",
    "        res_list = []\n",
    "        for i in range(data_size):\n",
    "            if query_idx[i] != data_size:\n",
    "                res_list.append((i, query_idx[i]))\n",
    "    \n",
    "        return res_list, len(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ca585e-09a9-4901-92b7-852fd4234c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(\n",
    "        num_pts: int = 500, \n",
    "        num_poses: int = 10, \n",
    "        translation_noise: float = 0.05, \n",
    "        rotation_noise: float = 0.1, \n",
    "        weight: float = 1.0,\n",
    "        batch_size: int = 1,\n",
    "        #dtype = torch.float32 # will get error if changed to torch.float64, don't know why\n",
    "        ) -> Tuple[List[th.Point3], List[th.SE3], List[th.SE3], List[GaussianSLAMEdge]]:\n",
    "    \"\"\"\n",
    "    create point clouds represented in different coordinates, record their ground truth \n",
    "    absolute pose, noisy absolute pose, also return an empty list to put loop edges\n",
    "\n",
    "    Returns:\n",
    "        point_list: a list stores points clouds, represented in different coordinates\n",
    "        abs_pose_list_gt: a list stores ground truth absolute poses\n",
    "        abs_pose_list: a list stores noisy (odometry) absolute poses\n",
    "        edge_list: a list stores custum GaussianSLAMEdge\n",
    "        TODO: Do I need to put the first edge that connets vertex_0 and vertex_1 into the list?\n",
    "    \"\"\"\n",
    "\n",
    "    points_0 = th.Point3(2*torch.rand(num_pts, 3)-1, name=\"POINT_CLOUD__0\") # initial points in world frame\n",
    "    point_list = [points_0] # represented in different frames\n",
    "    abs_pose_list_gt = [] # frame i to world frame\n",
    "    abs_pose_list = [] # frame i to world frame (noisy)\n",
    "    edge_list = []\n",
    "\n",
    "    abs_pose_list_gt.append(th.SE3(\n",
    "        #tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        tensor=torch.eye(3, 4).unsqueeze(0),\n",
    "        name=\"VERTEX_SE3_GT__0\"\n",
    "        ))\n",
    "    \n",
    "    abs_pose_list.append(th.SE3(\n",
    "        #tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        tensor=torch.eye(3, 4).unsqueeze(0),\n",
    "        name=\"VERTEX_SE3__0\"\n",
    "        ))\n",
    "\n",
    "    for idx in range(1, num_poses):\n",
    "\n",
    "        # ground truth relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_gt = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                torch.rand(batch_size, 3) - 0.5, \n",
    "                 2.0 * torch.rand(batch_size, 3 ) -1\n",
    "            ], dim=1),\n",
    "        )\n",
    "\n",
    "        # generate points represented in frame_{idx}\n",
    "        points = relative_pose_gt.transform_from(point_list[-1])\n",
    "        points.name = f\"POINT_CLOUD__{idx}\"\n",
    "        point_list.append(points)\n",
    "\n",
    "        # add noise to get odometry relative pose from frame_{idx-1} to frame_{idx}\n",
    "        \n",
    "        relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                translation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                rotation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "        )\n",
    "\n",
    "        relative_pose = cast(th.SE3, relative_pose_noise.compose(relative_pose_gt))\n",
    "        #relative_pose = cast(th.SE3, relative_pose_gt.compose(relative_pose_noise))\n",
    "        relative_pose.name = f\"EDGE_SE3__{idx-1}_{idx}\"\n",
    "        cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{idx-1}_{idx}\")\n",
    "\n",
    "        # absolute pose of frame_{idx}\n",
    "        absolute_pose_gt = cast(th.SE3, abs_pose_list_gt[-1].compose(relative_pose_gt.inverse()))\n",
    "        #absolute_pose_gt = cast(th.SE3, abs_pose_list_gt[-1].compose(relative_pose_gt))\n",
    "        absolute_pose_gt.name = f\"VERTEX_SE3_GT__{idx}\"\n",
    "\n",
    "        absolute_pose = cast(th.SE3, abs_pose_list[-1].compose(relative_pose.inverse()))\n",
    "        #absolute_pose = cast(th.SE3, abs_pose_list[-1].compose(relative_pose))\n",
    "        absolute_pose.name = f\"VERTEX_SE3__{idx}\"\n",
    "\n",
    "        abs_pose_list_gt.append(absolute_pose_gt)\n",
    "        abs_pose_list.append(absolute_pose)\n",
    "\n",
    "        # construct odometry edge between vertex_{idx-1} and vertex_{idx}\n",
    "        edge_list.append(GaussianSLAMEdge(idx-1, idx, relative_pose, cost_weight))\n",
    "\n",
    "    return point_list, abs_pose_list_gt, abs_pose_list, edge_list\n",
    "\n",
    "\n",
    "def add_loop_data(\n",
    "        i: int, \n",
    "        j: int, \n",
    "        abs_pose_list_gt: List[th.SE3], \n",
    "        edge_list: List[GaussianSLAMEdge],\n",
    "        weight: float = 1.0,\n",
    "        measurement_noise:float = 0.01,\n",
    "        batch_size: int = 1,\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Add loop closure between two arbitray coordinates i and j (i < j), and stores generated edge\n",
    "    \"\"\"\n",
    "\n",
    "    if i >= j:\n",
    "        raise ValueError(f\"The first frame index {i} is greater than the second frame index {j}!\")\n",
    "\n",
    "    abs_pose_i_gt = abs_pose_list_gt[i]\n",
    "    abs_pose_j_gt = abs_pose_list_gt[j]\n",
    "    rel_pose_ij_gt = th.SE3.compose(abs_pose_j_gt.inverse(), abs_pose_i_gt)\n",
    "    rel_pose_ij_gt.name = f\"EDGE_SE3_GT__{i}_{j}\"\n",
    "\n",
    "    relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "            )\n",
    "    rel_pose_ij = cast(th.SE3, relative_pose_noise.compose(rel_pose_ij_gt))\n",
    "    rel_pose_ij.name = f\"EDGE_SE3__{i}_{j}\"\n",
    "\n",
    "    cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{i}_{j}\")\n",
    "    edge = GaussianSLAMEdge(i, j, rel_pose_ij, cost_weight)\n",
    "    edge_list.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f203f103-9f98-4192-a018-1c5994203e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing a pose graph for Gaussian Splatting SLAM.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an odometry edge to pose graph.\n",
      "adding an loop edge to pose graph.\n",
      "cost_weight_mu = 2.0\n"
     ]
    }
   ],
   "source": [
    "point_list, abs_pose_gt_list, abs_pose_list, edge_list = create_data(\n",
    "    num_poses=10,\n",
    "    num_pts=100,\n",
    "    rotation_noise=0.1,\n",
    "    translation_noise=0.05\n",
    ")\n",
    "add_loop_data(0, 9, abs_pose_gt_list, edge_list)\n",
    "#add_loop_data(1, 8, abs_pose_gt_list, edge_list)\n",
    "#add_loop_data(2, 9, abs_pose_gt_list, edge_list)\n",
    "#add_loop_data(0, 9, abs_pose_gt_list, edge_list)\n",
    "\n",
    "\n",
    "rot_error_before = []\n",
    "trans_error_before = []\n",
    "for idx in range(len(abs_pose_list)):\n",
    "    abs_pose = abs_pose_list[idx]\n",
    "    rot = abs_pose.rotation().tensor.squeeze()\n",
    "    trans = abs_pose.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose_gt.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    rot_error_before.append(torch.acos((torch.trace(torch.matmul(rot.t(), rot_gt)) - 1) / 2))\n",
    "    #trans_error_before.append(torch.abs(trans @ trans_gt.t().squeeze()))\n",
    "    trans_error_before.append(torch.norm(trans - trans_gt))\n",
    "\n",
    "\n",
    "print(\"Constructing a pose graph for Gaussian Splatting SLAM.\")\n",
    "pose_graph = GaussianSLAMPoseGraph(requires_auto_grad=True)\n",
    "\n",
    "for edge in edge_list:\n",
    "    vertex_idx_i = edge.vertex_idx_i\n",
    "    vertex_idx_j = edge.vertex_idx_j\n",
    "    \n",
    "    vertex_i = abs_pose_list[vertex_idx_i]\n",
    "    vertex_j = abs_pose_list[vertex_idx_j]\n",
    "\n",
    "    if vertex_idx_j - vertex_idx_i == 1:\n",
    "        print(\"adding an odometry edge to pose graph.\")\n",
    "        pose_graph.add_odometry_edge(vertex_i, vertex_j, edge, point_list[vertex_idx_i].tensor)\n",
    "    else:\n",
    "        print(\"adding an loop edge to pose graph.\")\n",
    "        inlier_idx, num_matches = GaussianSLAMPoseGraph.match_gaussian_means(\n",
    "            point_list[vertex_idx_i].tensor, point_list[vertex_idx_j].tensor, edge.relative_pose.to_matrix().squeeze(), epsilon=5e-2)\n",
    "        inlier_idx_i = [idx[0] for idx in inlier_idx]\n",
    "        pose_graph.add_loop_closure_edge(vertex_i, vertex_j, edge, point_list[vertex_idx_i].tensor[inlier_idx_i, :], num_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726660be-ead6-45f9-bf7a-1f4beba699af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonlinearOptimizerInfo(best_solution={'VERTEX_SE3__0': tensor([[[ 1.0000e+00, -3.2835e-03,  9.4684e-04,  3.8103e-03],\n",
       "         [ 3.2858e-03,  1.0000e+00, -2.4134e-03,  8.3034e-04],\n",
       "         [-9.3891e-04,  2.4165e-03,  1.0000e+00, -1.7211e-03]]]), 'VERTEX_SE3__1': tensor([[[ 0.7452,  0.2528, -0.6170, -0.2593],\n",
       "         [-0.4842,  0.8413, -0.2402, -0.1890],\n",
       "         [ 0.4584,  0.4778,  0.7494, -0.1643]]]), 'VERTEX_SE3__2': tensor([[[ 0.3303, -0.2557, -0.9086, -0.2842],\n",
       "         [-0.9261,  0.0981, -0.3643, -0.0084],\n",
       "         [ 0.1822,  0.9618, -0.2044,  0.1588]]]), 'VERTEX_SE3__3': tensor([[[ 0.5591, -0.5053, -0.6573,  0.0555],\n",
       "         [-0.7359,  0.0627, -0.6742,  0.2174],\n",
       "         [ 0.3819,  0.8607, -0.3368,  0.0222]]]), 'VERTEX_SE3__4': tensor([[[ 0.1824,  0.4791, -0.8586,  0.0552],\n",
       "         [-0.8338, -0.3874, -0.3933,  0.0504],\n",
       "         [-0.5210,  0.7877,  0.3288,  0.3654]]]), 'VERTEX_SE3__5': tensor([[[-0.7348, -0.1973, -0.6490,  0.4393],\n",
       "         [-0.3438, -0.7164,  0.6071, -0.0790],\n",
       "         [-0.5847,  0.6692,  0.4585,  0.6736]]]), 'VERTEX_SE3__6': tensor([[[-0.9449,  0.2143, -0.2473,  0.8480],\n",
       "         [-0.3043, -0.2973,  0.9050,  0.1419],\n",
       "         [ 0.1204,  0.9304,  0.3462,  0.7674]]]), 'VERTEX_SE3__7': tensor([[[-0.2248, -0.5004, -0.8361,  0.7042],\n",
       "         [-0.7715, -0.4327,  0.4664,  0.4863],\n",
       "         [-0.5951,  0.7499, -0.2888,  0.4203]]]), 'VERTEX_SE3__8': tensor([[[ 0.7787, -0.4848, -0.3983,  0.3688],\n",
       "         [-0.4378, -0.8745,  0.2085,  0.2973],\n",
       "         [-0.4494,  0.0120, -0.8933,  0.1030]]]), 'VERTEX_SE3__9': tensor([[[ 0.9365,  0.0118,  0.3505,  0.0125],\n",
       "         [ 0.1793, -0.8750, -0.4496,  0.2069],\n",
       "         [ 0.3014,  0.4839, -0.8216, -0.0853]]]), 'line_process_0_9': tensor([[0.9999]])}, status=array([<NonlinearOptimizerStatus.CONVERGED: 1>], dtype=object), converged_iter=tensor([557]), best_iter=tensor([555]), err_history=None, last_err=tensor([0.0008]), best_err=tensor([0.0008]), state_history=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_graph._optimize(max_iterations=1e3, step_size=0.01, damping=0.01, verbose=False)\n",
    "#info = pose_graph.optimize_two_steps(max_iterations=1e3, step_size=0.01, l_ij_threshold=0.25, damping=0.2, verbose=False)\n",
    "#print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d735769b-ad5f-46c8-9532-13409866e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation error of vertex_0 before optimization 0.0, after optimization: 0.0\n",
      "Translation error of vertex_0 before optimization 0.0, after optimization: 0.004262770991772413\n",
      "\n",
      "Rotation error of vertex_1 before optimization 0.0013810680247843266, after optimization: 0.003126526717096567\n",
      "Translation error of vertex_1 before optimization 0.0013131033629179, after optimization: 0.004798325709998608\n",
      "\n",
      "Rotation error of vertex_2 before optimization 0.0009765625, after optimization: 0.0023920803796499968\n",
      "Translation error of vertex_2 before optimization 0.001915666158311069, after optimization: 0.0037466243375092745\n",
      "\n",
      "Rotation error of vertex_3 before optimization 0.0018269814318045974, after optimization: 0.0029296884313225746\n",
      "Translation error of vertex_3 before optimization 0.0025006108917295933, after optimization: 0.003270824206992984\n",
      "\n",
      "Rotation error of vertex_4 before optimization 0.0017605233006179333, after optimization: nan\n",
      "Translation error of vertex_4 before optimization 0.0023732867557555437, after optimization: 0.002721663098782301\n",
      "\n",
      "Rotation error of vertex_5 before optimization 0.0006905339541845024, after optimization: 0.0011960399569943547\n",
      "Translation error of vertex_5 before optimization 0.0029949939344078302, after optimization: 0.002553114900365472\n",
      "\n",
      "Rotation error of vertex_6 before optimization 0.0012918708380311728, after optimization: 0.0034526714589446783\n",
      "Translation error of vertex_6 before optimization 0.003475072793662548, after optimization: 0.002043691463768482\n",
      "\n",
      "Rotation error of vertex_7 before optimization 0.0011960399569943547, after optimization: 0.0036211926490068436\n",
      "Translation error of vertex_7 before optimization 0.004022927954792976, after optimization: 0.002327611204236746\n",
      "\n",
      "Rotation error of vertex_8 before optimization 0.000845727976411581, after optimization: 0.004256740212440491\n",
      "Translation error of vertex_8 before optimization 0.004249516408890486, after optimization: 0.0023529515601694584\n",
      "\n",
      "Rotation error of vertex_9 before optimization 0.0015440810238942504, after optimization: 0.0046834335662424564\n",
      "Translation error of vertex_9 before optimization 0.0041100881062448025, after optimization: 0.00341571937315166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rot_error_after = []\n",
    "trans_error_after = []\n",
    "for idx in range(len(abs_pose_list)):  \n",
    "    abs_pose_optimized = pose_graph._objective.get_optim_var(f\"VERTEX_SE3__{idx}\")\n",
    "    rot_opt = abs_pose_optimized.rotation().tensor.squeeze()\n",
    "    trans_opt = abs_pose_optimized.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose_gt.to_x_y_z_quaternion()[..., :3]\n",
    "\n",
    "    rot_error_after.append(torch.acos((torch.trace(torch.matmul(rot_opt.t(), rot_gt)) - 1) / 2))\n",
    "    #trans_error_after.append(torch.abs(trans_opt @ trans_gt.t().squeeze()))\n",
    "    trans_error_after.append(torch.norm(trans_opt - trans_gt))\n",
    "\n",
    "for idx in range(len(abs_pose_list)):  \n",
    "    print(f\"Rotation error of vertex_{idx} before optimization {rot_error_before[idx]}, after optimization: {rot_error_after[idx]}\")\n",
    "    print(f\"Translation error of vertex_{idx} before optimization {trans_error_before[idx]}, after optimization: {trans_error_after[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4699c2-bbdf-4092-a7bc-a72648edf144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test match_gaussian_means function\n",
    "pose_0, pose_1 = abs_pose_list[0], abs_pose_list[1]\n",
    "pose_01 = th.SE3.compose(pose_1.inverse(), pose_0).to_matrix().squeeze()\n",
    "idx, num = GaussianSLAMPoseGraph.match_gaussian_means(point_list[0].tensor, point_list[1].tensor, pose_01)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc33f380-46f8-4f94-b679-c4aceb630778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(pose_graph._objective.size_aux_vars())\n",
    "print(pose_graph._objective.size_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd2060-996b-447c-9825-ddd0f06a16a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d6531-1861-47a8-845c-4a0ce3851ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26af10-6b9d-4290-9496-ac253a98f6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca81778-b142-425a-85e5-45dff57e5198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
