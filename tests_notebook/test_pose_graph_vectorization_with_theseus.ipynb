{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a631bb5d-8346-46e5-b533-96342054211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import theseus as th\n",
    "import torchlie.functional as lieF # use this instead of th.SE3\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Union, List, Tuple, Optional, cast, Dict\n",
    "\n",
    "def torch2np(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\" Converts a PyTorch tensor to a NumPy ndarray.\n",
    "    Args:\n",
    "        tensor: The PyTorch tensor to convert.\n",
    "    Returns:\n",
    "        A NumPy ndarray with the same data and dtype as the input tensor.\n",
    "    \"\"\"\n",
    "    return tensor.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def to_skew_symmetric(tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Transform a (3, ) tensor to a (3, 3) tensor, or\n",
    "    Transform a (num_pts, 3) tensor to a (num_pts, 3, 3) tensor, or\n",
    "    Transform a (batch_size, num_pts, 3) tensor to a (batch_size, num_pts, 3, 3) tensor\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): 3d point cloud(s) that need(s) to be transformed to skew symmetric matrix\n",
    "\n",
    "    Returns:\n",
    "        skew_symmetric (torch.Tensor): transformed skew symmetric matrices\n",
    "    \"\"\"\n",
    "\n",
    "    tensor_shape = tensor.shape\n",
    "    if len(tensor_shape) > 3 or tensor_shape[-1] != 3:\n",
    "        raise ValueError(\"Incorrect tensor dimension!\")\n",
    "\n",
    "    if len(tensor_shape) == 1:\n",
    "        skew_symmetric = tensor.new_zeros((1, )+tensor_shape+(3, ))\n",
    "    else:\n",
    "        skew_symmetric = tensor.new_zeros(tensor_shape+(3, ))\n",
    "\n",
    "    skew_symmetric[..., 0, 1] = -tensor[..., 2]\n",
    "    skew_symmetric[..., 0, 2] = tensor[..., 1]\n",
    "    skew_symmetric[..., 1, 0] = tensor[..., 2]\n",
    "    skew_symmetric[..., 1, 2] = -tensor[..., 0]\n",
    "    skew_symmetric[..., 2, 0] = -tensor[..., 1]\n",
    "    skew_symmetric[..., 2, 1] = tensor[..., 0]\n",
    "\n",
    "    return skew_symmetric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca6a459-1add-481f-a25c-403a5a14aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSLAMEdge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vertex_idx_i: int,\n",
    "        vertex_idx_j: int,\n",
    "        relative_pose: th.SE3,\n",
    "        cost_weight: th.CostWeight\n",
    "    ):\n",
    "        self.vertex_idx_i = vertex_idx_i\n",
    "        self.vertex_idx_j = vertex_idx_j\n",
    "        self.relative_pose = relative_pose\n",
    "        self.cost_weight = cost_weight\n",
    "\n",
    "\n",
    "class GaussianSLAMPoseGraph:\n",
    "    def __init__(\n",
    "        self, \n",
    "        requires_auto_grad = True\n",
    "    ):\n",
    "        self._requires_auto_grad = requires_auto_grad\n",
    "        self._objective = th.Objective()\n",
    "        self._theseus_inputs = {} \n",
    "\n",
    "    def add_odometry_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        # (batch_size, num_pts, 3)\n",
    "        gaussian_means_th = th.Variable(\n",
    "            tensor=gaussian_means.unsqueeze(0), \n",
    "            name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\"\n",
    "        )\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            cost_function = th.AutoDiffCostFunction(\n",
    "                optim_vars=[vertex_i, vertex_j], \n",
    "                err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                dim=1, \n",
    "                cost_weight=edge.cost_weight, \n",
    "                aux_vars=[edge.relative_pose, gaussian_means_th]\n",
    "            )\n",
    "            self._objective.add(cost_function)\n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def add_loop_closure_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.tensor,\n",
    "            match_num: int, # kapa\n",
    "            tau: float=0.2, # fairly liberal distance threshold\n",
    "        ):\n",
    "        \n",
    "        cost_weight_registration = edge.cost_weight # for dense surface alignment\n",
    "        cost_weight_mu = cost_weight_registration.scale.tensor.squeeze() * np.sqrt(match_num) * tau\n",
    "        print(f\"cost_weight_mu = {cost_weight_mu}\")\n",
    "        cost_weight_line_process = th.ScaleCostWeight(cost_weight_mu) # for line process\n",
    "\n",
    "        l_ij = th.Vector(tensor=torch.ones(1, 1), name=f\"line_process_{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        gaussian_means_th = th.Variable(tensor=gaussian_means.unsqueeze(0), name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            cost_function_registration = th.AutoDiffCostFunction(\n",
    "                optim_vars=[vertex_i, vertex_j, l_ij], \n",
    "                err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                dim=1, \n",
    "                cost_weight=cost_weight_registration, \n",
    "                aux_vars=[edge.relative_pose, gaussian_means_th]\n",
    "            )\n",
    "            self._objective.add(cost_function_registration)\n",
    "\n",
    "            cost_function_line_process = th.AutoDiffCostFunction(\n",
    "                optim_vars=[l_ij,], \n",
    "                err_fn=GaussianSLAMPoseGraph.line_process, \n",
    "                dim=1, \n",
    "                cost_weight=cost_weight_line_process\n",
    "            )\n",
    "            self._objective.add(cost_function_line_process)\n",
    "        \n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor,\n",
    "                l_ij.name: l_ij.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def _remove_loop_outlier(self, threshold: float, substring=\"line_process\"):\n",
    "        \"\"\" \n",
    "        find all l_ij inside the objective, remove those whose value are smaller than threshold \n",
    "        and all cost functions that are connected to them\n",
    "        (currently implemented with the help of a dictionary called self._theseus_inputs, can it be\n",
    "        directly done with self._objective?)\n",
    "        \"\"\"\n",
    "        for key in self._theseus_inputs.keys():\n",
    "            if substring in key and self._objective.get_optim_var(key).tensor < threshold:\n",
    "                del self._theseus_inputs[key]\n",
    "                for cost_func in self._objective.get_functions_connected_to_optim_var(key):\n",
    "                    self._objective.erase(cost_func.name)\n",
    "\n",
    "    def _optimize(self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective=self._objective,\n",
    "            max_iterations=max_iterations,\n",
    "            step_size=step_size\n",
    "        )\n",
    "        layer = th.TheseusLayer(optimizer)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, info = layer.forward(\n",
    "                self._theseus_inputs, \n",
    "                optimizer_kwargs={\"damping\":damping, \"track_best_solution\":track_best_solution, \"verbose\":verbose}\n",
    "                )\n",
    "        return info\n",
    "\n",
    "    def optimize_two_steps(\n",
    "            self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            l_ij_threshold=0.25,\n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        optimization in two steps: \n",
    "        1. optimize with initial guess of all optim variables (T_i, l_ij)\n",
    "        2. remove all l_ij < threshold, and all cost functions that are connected to them,\n",
    "           optimize again with optimized variables\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"First step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        info = self._optimize(max_iterations, step_size, damping, track_best_solution, verbose)\n",
    "        self._remove_loop_outlier(threshold=l_ij_threshold)\n",
    "        print(f\"Second step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        # TODO: if all loops are true, no need to do second step optimization\n",
    "        info = self._optimize(max_iterations, step_size, damping, track_best_solution,verbose)\n",
    "        return info\n",
    "\n",
    "    @ staticmethod\n",
    "    def match_gaussian_means(\n",
    "        pts_1: torch.tensor,\n",
    "        pts_2: torch.tensor,\n",
    "        transformation: torch.tensor,\n",
    "        epsilon:float=5e-2\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Select inlier correspondences from two Gaussian clouds, use kd-tree to speed up\n",
    "    \n",
    "        Args:\n",
    "            pts_1, pts_2: mean positions of 3D Gaussians\n",
    "            transformation: prior transformation matrix from one Gaussian cloud to the other\n",
    "            epsilon: threshold for finding inlier correspondence\n",
    "    \n",
    "        Returns:\n",
    "            a list contains tuples of matching indices\n",
    "        \"\"\"\n",
    "        if transformation.size() != torch.Size([4, 4]):\n",
    "            raise ValueError(f\"The size of input transformation matrix must be (4, 4), but get {transformation.size()}\")\n",
    "    \n",
    "        if pts_1.size(-1) != 1:\n",
    "            pts_1 = pts_1.unsqueeze(-1)\n",
    "    \n",
    "        if isinstance(pts_1, th.Point3) or isinstance(pts_2, th.Point3):\n",
    "                raise TypeError(\"To be matched points must be torch.Tensor\")\n",
    "    \n",
    "        rotation = transformation[:3, :3]\n",
    "        translation = transformation[:3, 3]\n",
    "        pts_1_new = (rotation @ pts_1).squeeze() + translation\n",
    "    \n",
    "        pts_1_numpy = torch2np(pts_1_new)\n",
    "        pts_2_numpy = torch2np(pts_2)\n",
    "        pts2_kdtree = KDTree(pts_2_numpy)\n",
    "    \n",
    "        _, query_idx = pts2_kdtree.query(pts_1_numpy, distance_upper_bound=epsilon, workers=-1)\n",
    "    \n",
    "        data_size = pts_1.size()[0]\n",
    "        res_list = []\n",
    "        for i in range(data_size):\n",
    "            if query_idx[i] != data_size:\n",
    "                res_list.append((i, query_idx[i]))\n",
    "    \n",
    "        return res_list, len(res_list)\n",
    "\n",
    "    @ staticmethod\n",
    "    def dense_surface_alignment(\n",
    "        optim_vars: Union[Tuple[th.SE3, th.SE3], Tuple[th.SE3, th.SE3, th.Vector]],\n",
    "        aux_vars: Tuple[th.SE3, th.Variable]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the dense surface alignment error between two vertices, can be used as the error\n",
    "        function input to instantiate a th.CostFunction variable\n",
    "\n",
    "        Args:\n",
    "            optim_vars: optimizaiton variables registered in cost function, should contain\n",
    "                pose_i, pose_j: correction matrix for pose i, j\n",
    "                l_ij (optional): line process coefficient\n",
    "\n",
    "            aux_vars: auxiliary variables registered in cost function, should contain\n",
    "                relative_pose: constraint between vertex_i and vertex_j\n",
    "                gaussian_means_i: mean positions of the 3D Gaussians inside camera frustum, \n",
    "                    represented in coordinate i and coordinate (those in coordinate j are not needed),\n",
    "                    shape = (batch_size, num_pts, dim)\n",
    "\n",
    "        Returns:\n",
    "            square root of global place recognition error\n",
    "        \"\"\"\n",
    "        # determine whether the edge is odometry edge or loop closure edge\n",
    "        tuple_size = len(optim_vars)\n",
    "        if tuple_size == 2:\n",
    "            pose_i, pose_j = optim_vars\n",
    "        elif tuple_size == 3:\n",
    "            pose_i, pose_j, l_ij = optim_vars\n",
    "        else:\n",
    "            raise ValueError(f\"optim_vars tuple size is {tuple_size}, which can only be 2 or 3.\")\n",
    "        pose_ij_measurement, gaussian_means = aux_vars\n",
    "\n",
    "        pose_ij_odometry : th.SE3 = pose_j.inverse().compose(pose_i) # (batch_size, 3, 4)\n",
    "        pose_residual : th.SE3 = pose_ij_measurement.inverse().compose(pose_ij_odometry) # (batch_size, 3, 4)\n",
    "\n",
    "        rot_residual = pose_residual.rotation().log_map().unsqueeze(1) # (batch_size, 1, 3)\n",
    "        trans_residual = pose_residual.translation().tensor.unsqueeze(1) # (batch_size, 1, 3)\n",
    "        xi = torch.cat((rot_residual, trans_residual), dim=-1) # (batch_size, 1, 6)\n",
    "        \n",
    "        p_skew_symmetric = to_skew_symmetric(gaussian_means.tensor) # (batch_size, num_pts, 3, 3)\n",
    "        # tensor.expand() will not allocate new memory, modification on one sample will change values for all,\n",
    "        # use tensor.repeat() instead\n",
    "        G_p = torch.cat(( # (batch_size, num, 3, 6)\n",
    "            -p_skew_symmetric, \n",
    "            #torch.eye(3).repeat(gaussian_means.shape[0], gaussian_means.shape[-2], 1, 1)\n",
    "            torch.tile(torch.eye(3), (gaussian_means.shape[0], gaussian_means.shape[-2], 1, 1)),\n",
    "            ), dim=-1)\n",
    "        Lambda = torch.sum(G_p.transpose(-2, -1) @ G_p, axis=1) # (batch_size, 6, 6)\n",
    "        res = (xi @ Lambda @ xi.transpose(-2, -1)).squeeze(1) # (batch_size, 1)\n",
    "        \n",
    "        if tuple_size == 3:\n",
    "            return l_ij.tensor.sqrt() * res.sqrt()\n",
    "        else:\n",
    "            return res.sqrt()\n",
    "        \n",
    "    @ staticmethod\n",
    "    def line_process(optim_vars: th.Vector, aux_vars=None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the line process error of a loop closrue edge, can be used as the error\n",
    "        input to instantiate a th.CostFunction variable\n",
    "\n",
    "        Args:\n",
    "            optim_vars:\n",
    "                l_ij: jointly optimized weight (l_ij ∈ [0, 1]) over the loop edges\n",
    "                (note that the scaling factor mu is considered as cost_weight)\n",
    "\n",
    "        Returns:\n",
    "            square root of line process error\n",
    "        \"\"\"\n",
    "        l_ij, = optim_vars\n",
    "        return l_ij.tensor.sqrt() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4adbc01-500f-4500-b6ef-6135c1b0faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(\n",
    "        num_pts: int = 1000, \n",
    "        num_poses: int = 10, \n",
    "        translation_noise: float = 0.05, \n",
    "        rotation_noise: float = 0.1, \n",
    "        weight = 1.0,\n",
    "        batch_size: int = 1,\n",
    "        #dtype = torch.float32 # will get error if changed to torch.float64, don't know why\n",
    "        ) -> Tuple[List[th.Point3], List[th.SE3], List[th.SE3], List[GaussianSLAMEdge]]:\n",
    "    \"\"\"\n",
    "    create point clouds represented in different coordinates, record their ground truth \n",
    "    absolute pose, noisy absolute pose, also return an empty list to put loop edges\n",
    "\n",
    "    Returns:\n",
    "        point_list: a list stores points clouds, represented in different coordinates\n",
    "        abs_pose_list_gt: a list stores ground truth absolute poses\n",
    "        abs_pose_list: a list stores noisy (odometry) absolute poses\n",
    "        edge_list: a list stores custum GaussianSLAMEdge\n",
    "        TODO: Do I need to put the first edge that connets vertex_0 and vertex_1 into the list?\n",
    "    \"\"\"\n",
    "\n",
    "    points_0 = th.Point3(2*torch.rand(num_pts, 3)-1, name=\"POINT_CLOUD__0\") # initial points in world frame\n",
    "    point_list = [points_0] # represented in different frames\n",
    "    abs_pose_list_gt = [] # frame i to world frame\n",
    "    abs_pose_list = [] # frame i to world frame (noisy)\n",
    "    edge_list = []\n",
    "\n",
    "    abs_pose_list_gt.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3_GT__0\"\n",
    "        ))\n",
    "    \n",
    "    abs_pose_list.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3__0\"\n",
    "        ))\n",
    "\n",
    "    for idx in range(1, num_poses):\n",
    "\n",
    "        # ground truth relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_gt = th.SE3.exp_map(\n",
    "            torch.cat([torch.rand(batch_size, 3)-0.5, 2.0 * torch.rand(batch_size, 3)-1], dim=1),\n",
    "        )\n",
    "\n",
    "        # generate points represented in frame_{idx}\n",
    "        points = relative_pose_gt.transform_from(point_list[-1])\n",
    "        points.name = f\"POINT_CLOUD__{idx}\"\n",
    "        point_list.append(points)\n",
    "\n",
    "        # add noise to get odometry relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                translation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                rotation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "        )\n",
    "\n",
    "        relative_pose = cast(th.SE3, relative_pose_noise.compose(relative_pose_gt))\n",
    "        relative_pose.name = f\"EDGE_SE3__{idx-1}_{idx}\"\n",
    "        cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{idx-1}_{idx}\")\n",
    "\n",
    "        # absolute pose of frame_{idx}\n",
    "        absolute_pose_gt = cast(th.SE3, abs_pose_list_gt[-1].compose(relative_pose_gt.inverse()))\n",
    "        absolute_pose_gt.name = f\"VERTEX_SE3_GT__{idx}\"\n",
    "\n",
    "        absolute_pose = cast(th.SE3, abs_pose_list[-1].compose(relative_pose.inverse()))\n",
    "        absolute_pose.name = f\"VERTEX_SE3__{idx}\"\n",
    "\n",
    "        abs_pose_list_gt.append(absolute_pose_gt)\n",
    "        abs_pose_list.append(absolute_pose)\n",
    "\n",
    "        # construct odometry edge between vertex_{idx-1} and vertex_{idx}\n",
    "        edge_list.append(GaussianSLAMEdge(idx-1, idx, relative_pose, cost_weight))\n",
    "\n",
    "    return point_list, abs_pose_list_gt, abs_pose_list, edge_list\n",
    "\n",
    "\n",
    "def add_loop_data(\n",
    "        i: int, \n",
    "        j: int, \n",
    "        abs_pose_list_gt: List[th.SE3], \n",
    "        edge_list: List[GaussianSLAMEdge],\n",
    "        weight: float = 2.0,\n",
    "        measurement_noise:float = 0.001,\n",
    "        batch_size: int = 1,\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Add loop closure between two arbitray coordinates i and j (i < j), and stores generated edge\n",
    "    \"\"\"\n",
    "\n",
    "    if i >= j:\n",
    "        raise ValueError(f\"The first frame index {i} is greater than the second frame index {j}!\")\n",
    "\n",
    "    abs_pose_i_gt = abs_pose_list_gt[i]\n",
    "    abs_pose_j_gt = abs_pose_list_gt[j]\n",
    "    rel_pose_ij_gt = th.SE3.compose(abs_pose_j_gt.inverse(), abs_pose_i_gt)\n",
    "    rel_pose_ij_gt.name = f\"EDGE_SE3_GT__{i}_{j}\"\n",
    "\n",
    "    relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "            )\n",
    "    rel_pose_ij = cast(th.SE3, relative_pose_noise.compose(rel_pose_ij_gt))\n",
    "    rel_pose_ij.name = f\"EDGE_SE3__{i}_{j}\"\n",
    "\n",
    "    cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{i}_{j}\")\n",
    "    edge = GaussianSLAMEdge(i, j, rel_pose_ij, cost_weight)\n",
    "    edge_list.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3faea3e0-2cad-45d8-9a2a-b3343fed0d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing a pose graph for Gaussian Splatting SLAM.\n",
      "adding edge 0 to pose graph, current edge is an odometry edge.\n",
      "adding edge 1 to pose graph, current edge is an odometry edge.\n",
      "adding edge 2 to pose graph, current edge is an odometry edge.\n",
      "adding edge 3 to pose graph, current edge is an odometry edge.\n",
      "adding edge 4 to pose graph, current edge is an odometry edge.\n",
      "adding edge 5 to pose graph, current edge is an odometry edge.\n",
      "adding edge 6 to pose graph, current edge is an odometry edge.\n",
      "adding edge 7 to pose graph, current edge is an odometry edge.\n",
      "adding edge 8 to pose graph, current edge is an odometry edge.\n",
      "adding edge 9 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 4.0\n",
      "adding edge 10 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 4.0\n",
      "adding edge 11 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 2.190890312194824\n"
     ]
    }
   ],
   "source": [
    "point_list, abs_pose_gt_list, abs_pose_list, edge_list = create_data(\n",
    "    num_poses=10,\n",
    "    num_pts=100,\n",
    "    rotation_noise=0.1,\n",
    "    translation_noise=0.05\n",
    ")\n",
    "add_loop_data(0, 7, abs_pose_gt_list, edge_list, measurement_noise=1e-3)\n",
    "add_loop_data(1, 8, abs_pose_gt_list, edge_list, measurement_noise=1e-3)\n",
    "add_loop_data(2, 9, abs_pose_gt_list, edge_list, measurement_noise=1e-1)\n",
    "\n",
    "rot_error_before = []\n",
    "trans_error_before = []\n",
    "for idx in range(len(abs_pose_list)):\n",
    "    abs_pose = abs_pose_list[idx]\n",
    "    rot = abs_pose.rotation().tensor.squeeze()\n",
    "    trans = abs_pose.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose_gt.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    rot_error_before.append(torch.acos((torch.trace(torch.matmul(rot.t(), rot_gt)) - 1) / 2))\n",
    "    #trans_error_before.append(torch.abs(trans @ trans_gt.t().squeeze()))\n",
    "    trans_error_before.append(torch.norm(trans - trans_gt))\n",
    "\n",
    "\n",
    "print(\"Constructing a pose graph for Gaussian Splatting SLAM.\")\n",
    "pose_graph = GaussianSLAMPoseGraph(requires_auto_grad=True)\n",
    "\n",
    "for idx in range(len(edge_list)):\n",
    "    edge = edge_list[idx]\n",
    "    vertex_idx_i = edge.vertex_idx_i\n",
    "    vertex_idx_j = edge.vertex_idx_j\n",
    "    \n",
    "    vertex_i = abs_pose_list[vertex_idx_i]\n",
    "    vertex_j = abs_pose_list[vertex_idx_j]\n",
    "\n",
    "    if vertex_idx_j - vertex_idx_i == 1:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an odometry edge.\")\n",
    "        pose_graph.add_odometry_edge(vertex_i, vertex_j, edge, point_list[idx].tensor)\n",
    "    else:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an loop edge.\")\n",
    "        inlier_idx, num_matches = GaussianSLAMPoseGraph.match_gaussian_means(\n",
    "            point_list[vertex_idx_i].tensor, point_list[vertex_idx_j].tensor, edge.relative_pose.to_matrix().squeeze(), epsilon=5e-2)\n",
    "        inlier_idx_i = [idx_inlier[0] for idx_inlier in inlier_idx]\n",
    "        pose_graph.add_loop_closure_edge(vertex_i, vertex_j, edge, point_list[vertex_idx_i].tensor[inlier_idx_i, :], num_matches, tau=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d85c26d-3397-4d0c-a7b5-4ea7ddaa89a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonlinearOptimizerInfo(best_solution={'VERTEX_SE3__0': tensor([[[ 0.9958, -0.0797, -0.0459, -0.0276],\n",
       "         [ 0.0692,  0.9780, -0.1969,  0.1158],\n",
       "         [ 0.0606,  0.1928,  0.9794,  0.0507]]]), 'VERTEX_SE3__1': tensor([[[ 0.9908,  0.0381,  0.1302, -0.0533],\n",
       "         [-0.0276,  0.9963, -0.0813, -0.1701],\n",
       "         [-0.1328,  0.0769,  0.9881,  0.3852]]]), 'VERTEX_SE3__2': tensor([[[ 0.5183,  0.0870,  0.8507,  0.1567],\n",
       "         [-0.4843,  0.8498,  0.2082,  0.2775],\n",
       "         [-0.7049, -0.5199,  0.4826,  0.4262]]]), 'VERTEX_SE3__3': tensor([[[ 0.1168,  0.5042,  0.8556,  0.3942],\n",
       "         [ 0.0883,  0.8528, -0.5146, -0.2484],\n",
       "         [-0.9892,  0.1356,  0.0551,  0.6395]]]), 'VERTEX_SE3__4': tensor([[[ 0.4750,  0.6270,  0.6174,  0.4285],\n",
       "         [-0.0599,  0.7231, -0.6882, -0.1073],\n",
       "         [-0.8779,  0.2899,  0.3810,  0.9691]]]), 'VERTEX_SE3__5': tensor([[[ 0.9255, -0.1390,  0.3523, -0.0969],\n",
       "         [ 0.3663,  0.5647, -0.7395,  0.0589],\n",
       "         [-0.0962,  0.8135,  0.5736,  0.8370]]]), 'VERTEX_SE3__6': tensor([[[ 0.7981,  0.3211, -0.5098, -0.1491],\n",
       "         [-0.5522,  0.0517, -0.8321,  0.0792],\n",
       "         [-0.2409,  0.9456,  0.2186,  0.5734]]]), 'VERTEX_SE3__7': tensor([[[ 0.7494,  0.4189, -0.5127, -0.6107],\n",
       "         [-0.6489,  0.3110, -0.6944,  0.0295],\n",
       "         [-0.1314,  0.8531,  0.5049,  0.8157]]]), 'VERTEX_SE3__8': tensor([[[ 0.4283,  0.2422, -0.8706, -0.3478],\n",
       "         [-0.5661,  0.8228, -0.0496,  0.3065],\n",
       "         [ 0.7043,  0.5141,  0.4895,  0.6157]]]), 'VERTEX_SE3__9': tensor([[[ 0.6402,  0.5582, -0.5277, -0.0982],\n",
       "         [-0.1773,  0.7758,  0.6056,  0.3898],\n",
       "         [ 0.7475, -0.2941,  0.5957,  0.9329]]]), 'line_process_0_7': tensor([[0.9998]]), 'line_process_1_8': tensor([[0.9999]]), 'line_process_2_9': tensor([[0.9999]])}, status=array([<NonlinearOptimizerStatus.MAX_ITERATIONS: 2>], dtype=object), converged_iter=tensor([-1]), best_iter=tensor([915]), err_history=None, last_err=tensor([2.3241]), best_err=tensor([2.2317]), state_history=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#info = pose_graph.optimize_two_steps(max_iterations=1e3, step_size=0.05, l_ij_threshold=0.25, damping=0.1, verbose=False)\n",
    "#print(info)\n",
    "pose_graph._optimize(max_iterations=1e3, step_size=0.01, damping=0.01, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df56bca-6086-4e05-a733-d20d28dd28d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation error of vertex_0 before optimization 0.0, after optimization: nan\n",
      "Translation error of vertex_0 before optimization 0.0, after optimization: 0.0\n",
      "\n",
      "Rotation error of vertex_1 before optimization 0.12016863375902176, after optimization: 0.07247258722782135\n",
      "Translation error of vertex_1 before optimization 0.06856519728899002, after optimization: 0.058886561542749405\n",
      "\n",
      "Rotation error of vertex_2 before optimization 0.06997665017843246, after optimization: 0.07151468843221664\n",
      "Translation error of vertex_2 before optimization 0.09170907735824585, after optimization: 0.054567016661167145\n",
      "\n",
      "Rotation error of vertex_3 before optimization 0.15978862345218658, after optimization: 0.0964701697230339\n",
      "Translation error of vertex_3 before optimization 0.1356438845396042, after optimization: 0.13132673501968384\n",
      "\n",
      "Rotation error of vertex_4 before optimization 0.17929285764694214, after optimization: 0.04165314510464668\n",
      "Translation error of vertex_4 before optimization 0.16625680029392242, after optimization: 0.10867732763290405\n",
      "\n",
      "Rotation error of vertex_5 before optimization 0.30387380719184875, after optimization: 0.03313275799155235\n",
      "Translation error of vertex_5 before optimization 0.2399270087480545, after optimization: 0.15392327308654785\n",
      "\n",
      "Rotation error of vertex_6 before optimization 0.36959782242774963, after optimization: 0.10540898144245148\n",
      "Translation error of vertex_6 before optimization 0.16452020406723022, after optimization: 0.07862942665815353\n",
      "\n",
      "Rotation error of vertex_7 before optimization 0.43567708134651184, after optimization: 0.05729511007666588\n",
      "Translation error of vertex_7 before optimization 0.14827609062194824, after optimization: 0.028831660747528076\n",
      "\n",
      "Rotation error of vertex_8 before optimization 0.44447216391563416, after optimization: 0.04734000563621521\n",
      "Translation error of vertex_8 before optimization 0.2308434695005417, after optimization: 0.05517371743917465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rot_error_after = []\n",
    "trans_error_after = []\n",
    "\n",
    "abs_pose_optimized_0 = pose_graph._objective.get_optim_var(\"VERTEX_SE3__0\")\n",
    "for idx in range(len(abs_pose_list)):  \n",
    "    abs_pose_optimized = pose_graph._objective.get_optim_var(f\"VERTEX_SE3__{idx}\")\n",
    "    abs_pose_optimized = abs_pose_optimized_0.inverse().compose(abs_pose_optimized)\n",
    "    rot_opt = abs_pose_optimized.rotation().tensor.squeeze()\n",
    "    trans_opt = abs_pose_optimized.to_x_y_z_quaternion()[..., :3]\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose_gt.to_x_y_z_quaternion()[..., :3]\n",
    "\n",
    "    rot_error_after.append(torch.acos((torch.trace(torch.matmul(rot_opt.t(), rot_gt)) - 1) / 2))\n",
    "    #trans_error_after.append(torch.abs(trans_opt @ trans_gt.t().squeeze()))\n",
    "    trans_error_after.append(torch.norm(trans_opt - trans_gt))\n",
    "    \n",
    "\n",
    "for idx in range(len(abs_pose_list)-1):  \n",
    "    print(f\"Rotation error of vertex_{idx} before optimization {rot_error_before[idx]}, after optimization: {rot_error_after[idx]}\")\n",
    "    print(f\"Translation error of vertex_{idx} before optimization {trans_error_before[idx]}, after optimization: {trans_error_after[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d37f78-ad1a-4b4d-805c-ff35b9e40336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3).repeat(1, 2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755ecb4d-32b7-4b30-9eb5-4b98261e8593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(torch.eye(3), (1, 2, 1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10cee673-8f1d-49e4-b8aa-9b59070399fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(pose_graph._objective.size_aux_vars())\n",
    "print(pose_graph._objective.size_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d8001-c5fd-45b1-9468-f48b1e99bcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755a1ea-f241-49d3-8917-51922bba7ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
