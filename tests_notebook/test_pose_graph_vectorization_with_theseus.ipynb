{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a631bb5d-8346-46e5-b533-96342054211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import theseus as th\n",
    "import torchlie.functional as lieF # use this instead of th.SE3\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Union, List, Tuple, Optional, cast, Dict\n",
    "\n",
    "def torch2np(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\" Converts a PyTorch tensor to a NumPy ndarray.\n",
    "    Args:\n",
    "        tensor: The PyTorch tensor to convert.\n",
    "    Returns:\n",
    "        A NumPy ndarray with the same data and dtype as the input tensor.\n",
    "    \"\"\"\n",
    "    return tensor.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def to_skew_symmetric(tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Transform a (3, ) tensor to a (3, 3) tensor, or\n",
    "    Transform a (num_pts, 3) tensor to a (num_pts, 3, 3) tensor, or\n",
    "    Transform a (batch_size, num_pts, 3) tensor to a (batch_size, num_pts, 3, 3) tensor\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): 3d point cloud(s) that need(s) to be transformed to skew symmetric matrix\n",
    "\n",
    "    Returns:\n",
    "        skew_symmetric (torch.Tensor): transformed skew symmetric matrices\n",
    "    \"\"\"\n",
    "\n",
    "    tensor_shape = tensor.shape\n",
    "    if len(tensor_shape) > 3 or tensor_shape[-1] != 3:\n",
    "        raise ValueError(\"Incorrect tensor dimension!\")\n",
    "\n",
    "    if len(tensor_shape) == 1:\n",
    "        skew_symmetric = tensor.new_zeros((1, )+tensor_shape+(3, ))\n",
    "    else:\n",
    "        skew_symmetric = tensor.new_zeros(tensor_shape+(3, ))\n",
    "\n",
    "    skew_symmetric[..., 0, 1] = -tensor[..., 2]\n",
    "    skew_symmetric[..., 0, 2] = tensor[..., 1]\n",
    "    skew_symmetric[..., 1, 0] = tensor[..., 2]\n",
    "    skew_symmetric[..., 1, 2] = -tensor[..., 0]\n",
    "    skew_symmetric[..., 2, 0] = -tensor[..., 1]\n",
    "    skew_symmetric[..., 2, 1] = tensor[..., 0]\n",
    "\n",
    "    return skew_symmetric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca6a459-1add-481f-a25c-403a5a14aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSLAMEdge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vertex_idx_i: int,\n",
    "        vertex_idx_j: int,\n",
    "        relative_pose: th.SE3,\n",
    "        cost_weight: th.CostWeight\n",
    "    ):\n",
    "        self.vertex_idx_i = vertex_idx_i\n",
    "        self.vertex_idx_j = vertex_idx_j\n",
    "        self.relative_pose = relative_pose\n",
    "        self.cost_weight = cost_weight\n",
    "\n",
    "\n",
    "class GaussianSLAMPoseGraph:\n",
    "    def __init__(\n",
    "        self, \n",
    "        requires_auto_grad = True\n",
    "    ):\n",
    "        self._requires_auto_grad = requires_auto_grad\n",
    "        self._objective = th.Objective()\n",
    "        self._theseus_inputs = {} \n",
    "\n",
    "    def add_odometry_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        # (batch_size, num_pts, 3)\n",
    "        gaussian_means_th = th.Variable(\n",
    "            tensor=gaussian_means.unsqueeze(0), \n",
    "            name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\"\n",
    "        )\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            cost_function = th.AutoDiffCostFunction(\n",
    "                optim_vars=[vertex_i, vertex_j], \n",
    "                err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                dim=1, \n",
    "                cost_weight=edge.cost_weight, \n",
    "                aux_vars=[edge.relative_pose, gaussian_means_th]\n",
    "            )\n",
    "            self._objective.add(cost_function)\n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def add_loop_closure_edge(\n",
    "            self,\n",
    "            vertex_i: th.SE3,\n",
    "            vertex_j: th.SE3,\n",
    "            edge: GaussianSLAMEdge,\n",
    "            gaussian_means: torch.tensor,\n",
    "            match_num : int, # kapa\n",
    "            tau: float=0.2, # fairly liberal distance threshold\n",
    "        ):\n",
    "        \n",
    "        cost_weight_registration = edge.cost_weight # for dense surface alignment\n",
    "        cost_weight_mu = cost_weight_registration.scale.tensor.squeeze() * np.sqrt(match_num) * tau\n",
    "        print(f\"cost_weight_mu = {cost_weight_mu}\")\n",
    "        cost_weight_line_process = th.ScaleCostWeight(cost_weight_mu) # for line process\n",
    "\n",
    "        l_ij = th.Vector(tensor=torch.ones(1, 1), name=f\"line_process_{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        gaussian_means_th = th.Variable(tensor=gaussian_means.unsqueeze(0), name=f\"gaussian_means_odometry__{edge.vertex_idx_i}_{edge.vertex_idx_j}\")\n",
    "\n",
    "        if self._requires_auto_grad:\n",
    "            cost_function_registration = th.AutoDiffCostFunction(\n",
    "                optim_vars=[vertex_i, vertex_j, l_ij], \n",
    "                err_fn=GaussianSLAMPoseGraph.dense_surface_alignment, \n",
    "                dim=1, \n",
    "                cost_weight=cost_weight_registration, \n",
    "                aux_vars=[edge.relative_pose, gaussian_means_th]\n",
    "            )\n",
    "            self._objective.add(cost_function_registration)\n",
    "\n",
    "            cost_function_line_process = th.AutoDiffCostFunction(\n",
    "                optim_vars=[l_ij,], \n",
    "                err_fn=GaussianSLAMPoseGraph.line_process, \n",
    "                dim=1, \n",
    "                cost_weight=cost_weight_line_process\n",
    "            )\n",
    "            self._objective.add(cost_function_line_process)\n",
    "        \n",
    "            self._theseus_inputs.update({\n",
    "                vertex_i.name: vertex_i.tensor, \n",
    "                vertex_j.name: vertex_j.tensor,\n",
    "                l_ij.name: l_ij.tensor\n",
    "            })\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def _remove_loop_outlier(self, threshold: float, substring=\"line_process\"):\n",
    "        \"\"\" \n",
    "        find all l_ij inside the objective, remove those whose value are smaller than threshold \n",
    "        and all cost functions that are connected to them\n",
    "        (currently implemented with the help of a dictionary called self._theseus_inputs, can it be\n",
    "        directly done with self._objective?)\n",
    "        \"\"\"\n",
    "        for key in self._theseus_inputs.keys():\n",
    "            if substring in key and self._objective.get_optim_var(key).tensor < threshold:\n",
    "                del self._theseus_inputs[key]\n",
    "                for cost_func in self._objective.get_functions_connected_to_optim_var(key):\n",
    "                    self._objective.erase(cost_func.name)\n",
    "\n",
    "    def _optimize(self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective=self._objective,\n",
    "            max_iterations=max_iterations,\n",
    "            step_size=step_size\n",
    "        )\n",
    "        layer = th.TheseusLayer(optimizer)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, info = layer.forward(\n",
    "                self._theseus_inputs, \n",
    "                optimizer_kwargs={\"damping\":damping, \"track_best_solution\":track_best_solution, \"verbose\":verbose}\n",
    "                )\n",
    "        return info\n",
    "\n",
    "    def optimize_two_steps(\n",
    "            self, \n",
    "            max_iterations=1e3, \n",
    "            step_size=0.01, \n",
    "            l_ij_threshold=0.25,\n",
    "            damping=0.1,\n",
    "            track_best_solution=True, \n",
    "            verbose=False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        optimization in two steps: \n",
    "        1. optimize with initial guess of all optim variables (T_i, l_ij)\n",
    "        2. remove all l_ij < threshold, and all cost functions that are connected to them,\n",
    "           optimize again with optimized variables\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"First step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        info = self._optimize(max_iterations, step_size, damping, track_best_solution, verbose)\n",
    "        self._remove_loop_outlier(threshold=l_ij_threshold)\n",
    "        print(f\"Second step optimization, dealing with {self._objective.size_cost_functions()} cost functions\")\n",
    "        # TODO: if all loops are true, no need to do second step optimization\n",
    "        info = self._optimize(max_iterations, step_size, damping, track_best_solution,verbose)\n",
    "        return info\n",
    "\n",
    "    @ staticmethod\n",
    "    def match_gaussian_means(\n",
    "        pts_1: torch.tensor,\n",
    "        pts_2: torch.tensor,\n",
    "        transformation: torch.tensor,\n",
    "        epsilon:float=5e-2\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Select inlier correspondences from two Gaussian clouds, use kd-tree to speed up\n",
    "    \n",
    "        Args:\n",
    "            pts_1, pts_2: mean positions of 3D Gaussians\n",
    "            transformation: prior transformation matrix from one Gaussian cloud to the other\n",
    "            epsilon: threshold for finding inlier correspondence\n",
    "    \n",
    "        Returns:\n",
    "            a list contains tuples of matching indices\n",
    "        \"\"\"\n",
    "        if transformation.size() != torch.Size([4, 4]):\n",
    "            raise ValueError(f\"The size of input transformation matrix must be (4, 4), but get {transformation.size()}\")\n",
    "    \n",
    "        if pts_1.size(-1) != 1:\n",
    "            pts_1 = pts_1.unsqueeze(-1)\n",
    "    \n",
    "        if isinstance(pts_1, th.Point3) or isinstance(pts_2, th.Point3):\n",
    "                raise TypeError(\"To be matched points must be torch.Tensor\")\n",
    "    \n",
    "        rotation = transformation[:3, :3]\n",
    "        translation = transformation[:3, 3]\n",
    "        pts_1_new = (rotation @ pts_1).squeeze() + translation\n",
    "    \n",
    "        pts_1_numpy = torch2np(pts_1_new)\n",
    "        pts_2_numpy = torch2np(pts_2)\n",
    "        pts2_kdtree = KDTree(pts_2_numpy)\n",
    "    \n",
    "        _, query_idx = pts2_kdtree.query(pts_1_numpy, distance_upper_bound=epsilon, workers=-1)\n",
    "    \n",
    "        data_size = pts_1.size()[0]\n",
    "        res_list = []\n",
    "        for i in range(data_size):\n",
    "            if query_idx[i] != data_size:\n",
    "                res_list.append((i, query_idx[i]))\n",
    "    \n",
    "        return res_list, len(res_list)\n",
    "\n",
    "    @ staticmethod\n",
    "    def dense_surface_alignment(\n",
    "        optim_vars: Union[Tuple[th.SE3, th.SE3], Tuple[th.SE3, th.SE3, th.Vector]],\n",
    "        aux_vars: Tuple[th.SE3, th.Variable]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the dense surface alignment error between two vertices, can be used as the error\n",
    "        function input to instantiate a th.CostFunction variable\n",
    "\n",
    "        Args:\n",
    "            optim_vars: optimizaiton variables registered in cost function, should contain\n",
    "                pose_i, pose_j: correction matrix for pose i, j\n",
    "                l_ij (optional): line process coefficient\n",
    "\n",
    "            aux_vars: auxiliary variables registered in cost function, should contain\n",
    "                relative_pose: constraint between vertex_i and vertex_j\n",
    "                gaussian_means_i: mean positions of the 3D Gaussians inside camera frustum, \n",
    "                    represented in coordinate i and coordinate (those in coordinate j are not needed),\n",
    "                    shape = (batch_size, num_pts, dim)\n",
    "\n",
    "        Returns:\n",
    "            square root of global place recognition error\n",
    "        \"\"\"\n",
    "        # determine whether the edge is odometry edge or loop closure edge\n",
    "        tuple_size = len(optim_vars)\n",
    "        if tuple_size == 2:\n",
    "            pose_i, pose_j = optim_vars\n",
    "        elif tuple_size == 3:\n",
    "            pose_i, pose_j, l_ij = optim_vars\n",
    "        else:\n",
    "            raise ValueError(f\"optim_vars tuple size is {tuple_size}, which can only be 2 or 3.\")\n",
    "        pose_ij_measurement, gaussian_means = aux_vars\n",
    "\n",
    "        pose_ij_odometry : th.SE3 = pose_j.inverse().compose(pose_i) # (batch_size, 3, 4)\n",
    "        pose_residual : th.SE3 = pose_ij_measurement.inverse().compose(pose_ij_odometry) # (batch_size, 3, 4)\n",
    "\n",
    "        rot_residual = pose_residual.rotation().log_map().unsqueeze(1) # (batch_size, 1, 3)\n",
    "        trans_residual = pose_residual.translation().tensor.unsqueeze(1) # (batch_size, 1, 3)\n",
    "        xi = torch.cat((rot_residual, trans_residual), dim=-1) # (batch_size, 1, 6)\n",
    "        \n",
    "        p_skew_symmetric = to_skew_symmetric(gaussian_means.tensor) # (batch_size, num_pts, 3, 3)\n",
    "        # tensor.expand() will not allocate new memory, modification on one sample will change values for all,\n",
    "        # use tensor.repeat() instead\n",
    "        G_p = torch.cat(( # (batch_size, num, 3, 6)\n",
    "            -p_skew_symmetric, \n",
    "            #torch.eye(3).repeat(gaussian_means.shape[0], gaussian_means.shape[-2], 1, 1)\n",
    "            torch.tile(torch.eye(3), (gaussian_means.shape[0], gaussian_means.shape[-2], 1, 1)),\n",
    "            ), dim=-1)\n",
    "        Lambda = torch.sum(G_p.transpose(-2, -1) @ G_p, axis=1) # (batch_size, 6, 6)\n",
    "        res = (xi @ Lambda @ xi.transpose(-2, -1)).squeeze(1) # (batch_size, 1)\n",
    "        \n",
    "        if tuple_size == 3:\n",
    "            return l_ij.tensor.sqrt() * res.sqrt()\n",
    "        else:\n",
    "            return res.sqrt()\n",
    "        \n",
    "    @ staticmethod\n",
    "    def line_process(optim_vars: th.Vector, aux_vars=None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the line process error of a loop closrue edge, can be used as the error\n",
    "        input to instantiate a th.CostFunction variable\n",
    "\n",
    "        Args:\n",
    "            optim_vars:\n",
    "                l_ij: jointly optimized weight (l_ij âˆˆ [0, 1]) over the loop edges\n",
    "                (note that the scaling factor mu is considered as cost_weight)\n",
    "\n",
    "        Returns:\n",
    "            square root of line process error\n",
    "        \"\"\"\n",
    "        l_ij, = optim_vars\n",
    "        return l_ij.tensor.sqrt() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4adbc01-500f-4500-b6ef-6135c1b0faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(\n",
    "        num_pts: int = 1000, \n",
    "        num_poses: int = 10, \n",
    "        translation_noise: float = 0.05, \n",
    "        rotation_noise: float = 0.1, \n",
    "        weight = 1.0,\n",
    "        batch_size: int = 1,\n",
    "        #dtype = torch.float32 # will get error if changed to torch.float64, don't know why\n",
    "        ) -> Tuple[List[th.Point3], List[th.SE3], List[th.SE3], List[GaussianSLAMEdge]]:\n",
    "    \"\"\"\n",
    "    create point clouds represented in different coordinates, record their ground truth \n",
    "    absolute pose, noisy absolute pose, also return an empty list to put loop edges\n",
    "\n",
    "    Returns:\n",
    "        point_list: a list stores points clouds, represented in different coordinates\n",
    "        abs_pose_list_gt: a list stores ground truth absolute poses\n",
    "        abs_pose_list: a list stores noisy (odometry) absolute poses\n",
    "        edge_list: a list stores custum GaussianSLAMEdge\n",
    "        TODO: Do I need to put the first edge that connets vertex_0 and vertex_1 into the list?\n",
    "    \"\"\"\n",
    "\n",
    "    points_0 = th.Point3(2*torch.rand(num_pts, 3)-1, name=\"POINT_CLOUD__0\") # initial points in world frame\n",
    "    point_list = [points_0] # represented in different frames\n",
    "    abs_pose_list_gt = [] # frame i to world frame\n",
    "    abs_pose_list = [] # frame i to world frame (noisy)\n",
    "    edge_list = []\n",
    "\n",
    "    abs_pose_list_gt.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3_GT__0\"\n",
    "        ))\n",
    "    \n",
    "    abs_pose_list.append(th.SE3(\n",
    "        tensor=torch.tile(torch.eye(3, 4), [1, 1, 1]),\n",
    "        name=\"VERTEX_SE3__0\"\n",
    "        ))\n",
    "\n",
    "    for idx in range(1, num_poses):\n",
    "\n",
    "        # ground truth relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_gt = th.SE3.exp_map(\n",
    "            torch.cat([torch.rand(batch_size, 3)-0.5, 2.0 * torch.rand(batch_size, 3)-1], dim=1),\n",
    "        )\n",
    "\n",
    "        # generate points represented in frame_{idx}\n",
    "        points = relative_pose_gt.transform_from(point_list[-1])\n",
    "        points.name = f\"POINT_CLOUD__{idx}\"\n",
    "        point_list.append(points)\n",
    "\n",
    "        # add noise to get odometry relative pose from frame_{idx-1} to frame_{idx}\n",
    "        relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                translation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                rotation_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "        )\n",
    "\n",
    "        relative_pose = cast(th.SE3, relative_pose_noise.compose(relative_pose_gt))\n",
    "        relative_pose.name = f\"EDGE_SE3__{idx-1}_{idx}\"\n",
    "        cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{idx-1}_{idx}\")\n",
    "\n",
    "        # absolute pose of frame_{idx}\n",
    "        absolute_pose_gt = cast(th.SE3, abs_pose_list_gt[-1].compose(relative_pose_gt.inverse()))\n",
    "        absolute_pose_gt.name = f\"VERTEX_SE3_GT__{idx}\"\n",
    "\n",
    "        absolute_pose = cast(th.SE3, abs_pose_list[-1].compose(relative_pose.inverse()))\n",
    "        absolute_pose.name = f\"VERTEX_SE3__{idx}\"\n",
    "\n",
    "        abs_pose_list_gt.append(absolute_pose_gt)\n",
    "        abs_pose_list.append(absolute_pose)\n",
    "\n",
    "        # construct odometry edge between vertex_{idx-1} and vertex_{idx}\n",
    "        edge_list.append(GaussianSLAMEdge(idx-1, idx, relative_pose, cost_weight))\n",
    "\n",
    "    return point_list, abs_pose_list_gt, abs_pose_list, edge_list\n",
    "\n",
    "\n",
    "def add_loop_data(\n",
    "        i: int, \n",
    "        j: int, \n",
    "        abs_pose_list_gt: List[th.SE3], \n",
    "        edge_list: List[GaussianSLAMEdge],\n",
    "        weight: float = 2.0,\n",
    "        measurement_noise:float = 0.001,\n",
    "        batch_size: int = 1,\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Add loop closure between two arbitray coordinates i and j (i < j), and stores generated edge\n",
    "    \"\"\"\n",
    "\n",
    "    if i >= j:\n",
    "        raise ValueError(f\"The first frame index {i} is greater than the second frame index {j}!\")\n",
    "\n",
    "    abs_pose_i_gt = abs_pose_list_gt[i]\n",
    "    abs_pose_j_gt = abs_pose_list_gt[j]\n",
    "    rel_pose_ij_gt = th.SE3.compose(abs_pose_j_gt.inverse(), abs_pose_i_gt)\n",
    "    rel_pose_ij_gt.name = f\"EDGE_SE3_GT__{i}_{j}\"\n",
    "\n",
    "    relative_pose_noise = th.SE3.exp_map(\n",
    "            torch.cat([\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "                measurement_noise * (2.0 * torch.rand(batch_size, 3) - 1),\n",
    "            ] ,dim=1),\n",
    "            )\n",
    "    rel_pose_ij = cast(th.SE3, relative_pose_noise.compose(rel_pose_ij_gt))\n",
    "    rel_pose_ij.name = f\"EDGE_SE3__{i}_{j}\"\n",
    "\n",
    "    cost_weight = th.ScaleCostWeight(weight, name=f\"EDGE_WEIGHT__{i}_{j}\")\n",
    "    edge = GaussianSLAMEdge(i, j, rel_pose_ij, cost_weight)\n",
    "    edge_list.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3faea3e0-2cad-45d8-9a2a-b3343fed0d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing a pose graph for Gaussian Splatting SLAM.\n",
      "adding edge 0 to pose graph, current edge is an odometry edge.\n",
      "adding edge 1 to pose graph, current edge is an odometry edge.\n",
      "adding edge 2 to pose graph, current edge is an odometry edge.\n",
      "adding edge 3 to pose graph, current edge is an odometry edge.\n",
      "adding edge 4 to pose graph, current edge is an odometry edge.\n",
      "adding edge 5 to pose graph, current edge is an odometry edge.\n",
      "adding edge 6 to pose graph, current edge is an odometry edge.\n",
      "adding edge 7 to pose graph, current edge is an odometry edge.\n",
      "adding edge 8 to pose graph, current edge is an odometry edge.\n",
      "adding edge 9 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 12.649110794067383\n",
      "adding edge 10 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 12.649110794067383\n",
      "adding edge 11 to pose graph, current edge is an loop edge.\n",
      "cost_weight_mu = 12.649110794067383\n"
     ]
    }
   ],
   "source": [
    "point_list, abs_pose_gt_list, abs_pose_list, edge_list = create_data()\n",
    "add_loop_data(0, 7, abs_pose_gt_list, edge_list)\n",
    "add_loop_data(1, 8, abs_pose_gt_list, edge_list)\n",
    "add_loop_data(2, 9, abs_pose_gt_list, edge_list)\n",
    "\n",
    "rot_error_before = []\n",
    "trans_error_before = []\n",
    "for idx in range(len(abs_pose_list)):\n",
    "    abs_pose = abs_pose_list[idx]\n",
    "    rot = abs_pose.rotation().tensor.squeeze()\n",
    "    trans = abs_pose.translation().tensor\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose.translation().tensor\n",
    "    \n",
    "    rot_error_before.append(torch.acos((torch.trace(torch.matmul(rot.t(), rot_gt)) - 1) / 2))\n",
    "    trans_error_before.append(torch.abs(trans @ trans_gt.t().squeeze()))\n",
    "\n",
    "\n",
    "print(\"Constructing a pose graph for Gaussian Splatting SLAM.\")\n",
    "pose_graph = GaussianSLAMPoseGraph(requires_auto_grad=True)\n",
    "\n",
    "for idx in range(len(edge_list)):\n",
    "    edge = edge_list[idx]\n",
    "    vertex_idx_i = edge.vertex_idx_i\n",
    "    vertex_idx_j = edge.vertex_idx_j\n",
    "    \n",
    "    vertex_i = abs_pose_list[vertex_idx_i]\n",
    "    vertex_j = abs_pose_list[vertex_idx_j]\n",
    "\n",
    "    if vertex_idx_j - vertex_idx_i == 1:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an odometry edge.\")\n",
    "        pose_graph.add_odometry_edge(vertex_i, vertex_j, edge, point_list[idx].tensor)\n",
    "    else:\n",
    "        print(f\"adding edge {idx} to pose graph, current edge is an loop edge.\")\n",
    "        inlier_idx, num_matches = GaussianSLAMPoseGraph.match_gaussian_means(\n",
    "            point_list[vertex_idx_i].tensor, point_list[vertex_idx_j].tensor, edge.relative_pose.to_matrix().squeeze(), epsilon=5e-2)\n",
    "        inlier_idx_i = [idx_inlier[0] for idx_inlier in inlier_idx]\n",
    "        pose_graph.add_loop_closure_edge(vertex_i, vertex_j, edge, point_list[vertex_idx_i].tensor[inlier_idx_i, :], num_matches, tau=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d85c26d-3397-4d0c-a7b5-4ea7ddaa89a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First step optimization, dealing with 15 cost functions\n",
      "Second step optimization, dealing with 15 cost functions\n",
      "NonlinearOptimizerInfo(best_solution={'VERTEX_SE3__0': tensor([[[ 0.9967,  0.0627, -0.0524, -0.0174],\n",
      "         [-0.0641,  0.9976, -0.0255, -0.0143],\n",
      "         [ 0.0507,  0.0288,  0.9983, -0.0517]]]), 'VERTEX_SE3__1': tensor([[[ 0.7357, -0.5913,  0.3304,  0.0890],\n",
      "         [ 0.1662,  0.6305,  0.7582,  0.2937],\n",
      "         [-0.6566, -0.5029,  0.5621, -0.4849]]]), 'VERTEX_SE3__2': tensor([[[ 0.7741, -0.3741,  0.5106,  0.1566],\n",
      "         [-0.0653,  0.7552,  0.6523,  0.6237],\n",
      "         [-0.6296, -0.5383,  0.5602, -0.6817]]]), 'VERTEX_SE3__3': tensor([[[-0.1135, -0.4142,  0.9031,  0.0714],\n",
      "         [ 0.4462,  0.7909,  0.4188,  0.6758],\n",
      "         [-0.8877,  0.4505,  0.0951, -0.5051]]]), 'VERTEX_SE3__4': tensor([[[ 0.5421, -0.1870,  0.8192, -0.0935],\n",
      "         [ 0.8339,  0.2397, -0.4971,  0.8443],\n",
      "         [-0.1034,  0.9527,  0.2859, -0.0371]]]), 'VERTEX_SE3__5': tensor([[[ 0.1213, -0.9631,  0.2402, -0.0135],\n",
      "         [ 0.9419,  0.0353, -0.3341,  1.0111],\n",
      "         [ 0.3133,  0.2668,  0.9114,  0.3324]]]), 'VERTEX_SE3__6': tensor([[[-0.2382, -0.9553, -0.1749, -0.2549],\n",
      "         [ 0.9421, -0.1835, -0.2807,  1.2636],\n",
      "         [ 0.2361, -0.2317,  0.9437,  0.4332]]]), 'VERTEX_SE3__7': tensor([[[-0.4730, -0.7286, -0.4954, -0.2890],\n",
      "         [ 0.6336,  0.1093, -0.7659,  1.2770],\n",
      "         [ 0.6121, -0.6762,  0.4099,  0.6583]]]), 'VERTEX_SE3__8': tensor([[[ 0.0479, -0.4468, -0.8933, -0.3664],\n",
      "         [ 0.6053,  0.7244, -0.3299,  1.1379],\n",
      "         [ 0.7946, -0.5249,  0.3052,  0.7592]]]), 'VERTEX_SE3__9': tensor([[[-0.3249, -0.7117, -0.6228,  0.1802],\n",
      "         [ 0.1806,  0.5997, -0.7796,  1.1976],\n",
      "         [ 0.9283, -0.3658, -0.0663,  0.7761]]]), 'line_process_0_7': tensor([[0.9999]]), 'line_process_1_8': tensor([[0.9999]]), 'line_process_2_9': tensor([[0.9999]])}, status=array([<NonlinearOptimizerStatus.MAX_ITERATIONS: 2>], dtype=object), converged_iter=tensor([-1]), best_iter=tensor([275]), err_history=None, last_err=tensor([35.7030]), best_err=tensor([30.8966]), state_history=None)\n"
     ]
    }
   ],
   "source": [
    "info = pose_graph.optimize_two_steps(max_iterations=1e3, step_size=0.02, l_ij_threshold=0.25, damping=0.1, verbose=False)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df56bca-6086-4e05-a733-d20d28dd28d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation error of vertex_0 before optimization 0.0, after optimization: 0.08538861572742462\n",
      "Translation error of vertex_0 before optimization tensor([0.]), after optimization: tensor([0.0559])\n",
      "\n",
      "Rotation error of vertex_1 before optimization 0.10006792098283768, after optimization: 0.13244080543518066\n",
      "Translation error of vertex_1 before optimization tensor([0.3377]), after optimization: tensor([0.0175])\n",
      "\n",
      "Rotation error of vertex_2 before optimization 0.07194383442401886, after optimization: 0.10689190775156021\n",
      "Translation error of vertex_2 before optimization tensor([0.9590]), after optimization: tensor([0.2433])\n",
      "\n",
      "Rotation error of vertex_3 before optimization 0.13692331314086914, after optimization: 0.1700340062379837\n",
      "Translation error of vertex_3 before optimization tensor([0.7582]), after optimization: tensor([0.4397])\n",
      "\n",
      "Rotation error of vertex_4 before optimization 0.16074852645397186, after optimization: 0.18198218941688538\n",
      "Translation error of vertex_4 before optimization tensor([0.7241]), after optimization: tensor([0.9752])\n",
      "\n",
      "Rotation error of vertex_5 before optimization 0.11181706190109253, after optimization: 0.11149931699037552\n",
      "Translation error of vertex_5 before optimization tensor([1.1097]), after optimization: tensor([1.4501])\n",
      "\n",
      "Rotation error of vertex_6 before optimization 0.14579986035823822, after optimization: 0.11471232026815414\n",
      "Translation error of vertex_6 before optimization tensor([1.7967]), after optimization: tensor([1.8022])\n",
      "\n",
      "Rotation error of vertex_7 before optimization 0.1717904508113861, after optimization: 0.09851297736167908\n",
      "Translation error of vertex_7 before optimization tensor([2.0603]), after optimization: tensor([1.9852])\n",
      "\n",
      "Rotation error of vertex_8 before optimization 0.1776786893606186, after optimization: 0.10465624183416367\n",
      "Translation error of vertex_8 before optimization tensor([2.0242]), after optimization: tensor([1.8837])\n",
      "\n",
      "Rotation error of vertex_9 before optimization 0.2647689878940582, after optimization: 0.14870290458202362\n",
      "Translation error of vertex_9 before optimization tensor([1.9734]), after optimization: tensor([2.0597])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rot_error_after = []\n",
    "trans_error_after = []\n",
    "for idx in range(len(abs_pose_list)):  \n",
    "    abs_pose_optimized = pose_graph._objective.get_optim_var(f\"VERTEX_SE3__{idx}\")\n",
    "    rot_opt = abs_pose_optimized.rotation().tensor.squeeze()\n",
    "    trans_opt = abs_pose_optimized.translation().tensor\n",
    "    \n",
    "    abs_pose_gt = abs_pose_gt_list[idx]\n",
    "    rot_gt = abs_pose_gt.rotation().tensor.squeeze()\n",
    "    trans_gt = abs_pose.translation().tensor\n",
    "\n",
    "    rot_error_after.append(torch.acos((torch.trace(torch.matmul(rot_opt.t(), rot_gt)) - 1) / 2))\n",
    "    trans_error_after.append(torch.abs(trans_opt @ trans_gt.t().squeeze()))\n",
    "\n",
    "for idx in range(len(abs_pose_list)):  \n",
    "    print(f\"Rotation error of vertex_{idx} before optimization {rot_error_before[idx]}, after optimization: {rot_error_after[idx]}\")\n",
    "    print(f\"Translation error of vertex_{idx} before optimization {trans_error_before[idx]}, after optimization: {trans_error_after[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d37f78-ad1a-4b4d-805c-ff35b9e40336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3).repeat(1, 2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755ecb4d-32b7-4b30-9eb5-4b98261e8593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(torch.eye(3), (1, 2, 1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10cee673-8f1d-49e4-b8aa-9b59070399fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(pose_graph._objective.size_aux_vars())\n",
    "print(pose_graph._objective.size_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d8001-c5fd-45b1-9468-f48b1e99bcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755a1ea-f241-49d3-8917-51922bba7ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
